<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SheronW</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://sheronw.github.io/"/>
  <updated>2019-03-28T18:43:01.992Z</updated>
  <id>http://sheronw.github.io/</id>
  
  <author>
    <name>SheronW</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>我果然一直都在无效学习</title>
    <link href="http://sheronw.github.io/2019/03/27/make_it_stick/"/>
    <id>http://sheronw.github.io/2019/03/27/make_it_stick/</id>
    <published>2019-03-28T03:39:14.000Z</published>
    <updated>2019-03-28T18:43:01.992Z</updated>
    
    <content type="html"><![CDATA[<p>高中的时候，由于被整个大环境洗了脑，我拿出了前所未有的干劲，开始随着全日制高中每一个小时都被安排好的作息，做出一副每时每刻都在好好学习的样子，但我很快就意识到，自己对所谓『知识』的掌握程度并不好，以至于到底学到了什么，我自己也说不出来。虽然隐约地觉得自己的学习方式可能出了些问题，但那时的我更认为自己只是还不够努力，只要没有学到死就没有资格去考虑这个问题，至于那些取得好成绩的同学，我统统将他们纳入天赋异禀的范畴。</p><p>直到这个春假忙里偷闲地看了本叫做『<a href="https://books.google.com/books/about/Make_It_Stick.html?id=t9JoAwAAQBAJ&amp;source=kp_book_description" target="_blank" rel="external">Make It Stick</a>』的书，自己隐约的猜想才算成了现实——是的，我之前接近二十年的人生中，很多时候的所谓『学习』都是无效的，为什么？因为没有动脑。现在想来，正如高中的我相信自己可以靠一点睡五点半起来取得好成绩一样，其实只是自己感动自己罢了——因为认真地去分析、去记忆很累，因此把时间用来不断地反复理解或记忆表层的内容，然后觉得自己应该掌握了，然后直接跳到下一个知识点。</p><p>这本书里面提到了一个叫做effortful learning的概念，其实这东西没什么可解释的，就是动脑子学的意思，基本上是个学生可能都能明白『真正动脑子学』是什么意思。我先解释一下为什么很多人都做不到effortful learning，然后再直接上方法论，至于effortful learning的益处暂时略去不谈，一些心理学和神经科学的原理我也不解释了。另外，书中针对教育者（父母、老师、培训机构等）也有一些针对性的建议，这里也略去不谈，以下内容主要针对像我这样的（苦逼）学生。<br><a id="more"></a></p><h1 id="为什么会无效学习"><a href="#为什么会无效学习" class="headerlink" title="为什么会无效学习"></a>为什么会无效学习</h1><h2 id="有效学习的缓慢与困难"><a href="#有效学习的缓慢与困难" class="headerlink" title="有效学习的缓慢与困难"></a>有效学习的缓慢与困难</h2><p>印象中第一次接触到所谓的『有效学习』，是在初中快会考的时候，历史老师建议我们晚上睡觉前把眼一闭，想一想自己这一天都学了什么，还有哪些需要学习或者改进的（其实就是之后我会提到的retrieval和reflection）。我想了想好有道理诶，然而坚持了一天就放弃了。</p><p>原因很简单，浪了一整天之后，晚上躺在床上的时候就已经很累了，回忆当天学了啥真的太难了，要很努力才能回忆起来，还不如看会儿<del>里</del>番放飞自我。</p><p>于是我用自己的亲身经历告诉了大家effortful learning有多困难。但是事实上，当你在努力回忆今天学了什么的时候，即使最后也没法全想出来，也是对学习很有利的。或者说，如果你回忆或者复习的时候越吃力，其实学到的东西就更多，真正掌握知识的学习曲线是很陡峭的。</p><p>可惜大多数人（比如我）都只是大概扫一眼，从来不在脑子里自己过一遍知识，把整个思考过程都复原一遍，因为『这么思考下去太慢了，肯定做不完作业』，想着『啊我觉得我应该会了吧』，就开始盲目地练习一些比较简单的题，如果会做更加引证了自己会做的假象，不会做就抄抄课本和笔记，照葫芦画瓢也能做出来，想着『那就考试之前看一下笔记吧』，也就这么搁置了下去。</p><p>除了学习曲线缓慢之外，effortful learning的过程中还有很多困难，比如下课之后回忆起之前课上讲过的内容，就会发现自己很多内容都不记得了，或者说认认真真做题不看课本的时候发现自己很多概念并不理解所以并不会做之类的。</p><p>不过这个也不用太担心，因为不断地试错错，即使最后都没做对，同样有利于学习。</p><p>这里灌一下原书提到的一段鸡汤：</p><blockquote><p>People who believe that their intellectual ability is fixed from birth, wired in their genes, tend to avoid challenges at which they may not succeed, because failure would appear to be an indication of lesser native ability.<br>By contrast, people who are helped to understand that effort and learning change the brain, and that their intellectual abilities lie to a large degree within their own control, are more likely to tackle difficult challenges and persist at them. They view failure as a sign of effort and as a turn in the road rather than as a measure of inability and the end of the road.<br>如果一个人相信自己的智力是与生俱来、嵌在基因里的，那么他会倾向于避免他们可能做不到的挑战，因为失败就代表着他们的先天能力不足。<br>与之相反地，如果一个人经过指点，明白努力和学习可以改变自己的大脑，并且自己的智力在很大程度上都是可以受自己控制，那么他就会更可能解决困难的挑战并在这上面坚持下去。他们将失败看作努力的证明或是一个转折点，而不是无能的标志或是死路一条。</p></blockquote><h2 id="知识被掌握的假象"><a href="#知识被掌握的假象" class="headerlink" title="知识被掌握的假象"></a>知识被掌握的假象</h2><p>只要说到复习，我做出的实际行动其实永远只有一项——『看错题和笔记』，真的只是来来回回地看，看到觉得自己好像已经背下来了就停下。其实我也知道最好的方式是重新做一遍，但想了想觉得自己既然已经重新做过一遍了，那么应该就不用再做、只要看看错在那里应该就会了。</p><p>于是我又中枪了——事实证明反反复复阅读笔记和文本是效率最低下的复习方式，因为缺少更深层的思考，很多时候我们只是掌握了『文本』，而不是『知识』本身。</p><p>更糟糕的是，这种『付出努力』的错觉，更加强化了我的错误认知，让我自己认为自己对于知识的掌握已经很熟练了，然后陷入了死循环。</p><p>心理学中的Imagination Inflation说的就是这种情况，如果一个人幻想过发生了某事，那么最后他真的会把它当真。我幻想反复阅读文本就能掌握知识，结果最后自己真的相信我已经把这些都学会了。</p><p>想要打破这种幻象，就要给自己设定一些指标，然后检查自己是否能够达到这些要求。对于一些没有硬性指标的抽象内容，可以时不时进行自测，或者和同学相互交流学习的内容。</p><h1 id="如何做到有效地学习"><a href="#如何做到有效地学习" class="headerlink" title="如何做到有效地学习"></a>如何做到有效地学习</h1><p>以下内容全部出自原书第八章。其实很多技巧我们都早已知道，只是由于思维惰性却迟迟不去实践。虽然开始改变很难，并且没啥成就感，但贵在坚持。</p><h2 id="Practice-Retrieving-New-Learning-from-memory"><a href="#Practice-Retrieving-New-Learning-from-memory" class="headerlink" title="Practice Retrieving New Learning from memory"></a>Practice Retrieving New Learning from memory</h2><p>有的时候，学到的知识其实已经储存到我们的大脑里了，只是我们仍然无法在需要的时候熟练调用。因此我们要为『调用』这个过程进行足够的练习。</p><p>首先，在学习，尤其是容易出现掌握假象的阅读笔记和文本时，要时不时停下来考虑以下几个问题：</p><ul><li>这些文本的要点有哪些？</li><li>其中有哪些我不熟悉的术语？如何定义它们？</li><li>其中有哪些我不熟悉的观点？如何把它们和我已知的内容连系起来？</li></ul><p>其次，<del>虽然大家都知道，</del>不要满足于翻来覆去地看课本和笔记，所有的知识最好都在脑子里自己重构一遍，并且课后习题做起来（除了练习retreving之外，也可以作为自己掌握程度的指标）。</p><p>当然，不要忘了每个周、每个月还有考试前温习学过的内容。</p><h2 id="Space-Out-Your-Retrieval-Practice"><a href="#Space-Out-Your-Retrieval-Practice" class="headerlink" title="Space Out Your Retrieval Practice"></a>Space Out Your Retrieval Practice</h2><p>首先，从真正掌握知识的角度上看，考前临时抱佛脚什么的绝对不可取，记得快忘得更快。因为知识需要时间来巩固，因此将知识分块，中间给予时间间隔的话学习效果更好。</p><p>对名词和脸来说，学完了如果不立刻复习的话很容易忘记。对于文本类的话，当天也要复习一次，一个月后一定要重新复习。</p><p>对于自己已经掌握的内容，也依然要复习。可以使用Leitner Box来管理自己掌握程度不同的知识。</p><p>不要总是学一种科目，在不同的科目间切换效果会更好。</p><h2 id="Interleave-the-Study-of-Different-Problem-types"><a href="#Interleave-the-Study-of-Different-Problem-types" class="headerlink" title="Interleave the Study of Different Problem types"></a>Interleave the Study of Different Problem types</h2><p>比起一口气突击一个知识点并进行盲目的单项训练，同时学习几个知识点，并且比较它们的相同点和不同点更好。</p><h2 id="Other-Effective-Study-Strategies"><a href="#Other-Effective-Study-Strategies" class="headerlink" title="Other Effective Study Strategies"></a>Other Effective Study Strategies</h2><h3 id="Elaboration"><a href="#Elaboration" class="headerlink" title="Elaboration"></a>Elaboration</h3><ul><li>试图用自己的话来总结所学知识</li><li>将所学内容与生活联系起来</li><li>寻找新知识与已知知识的关系<h3 id="Generation"><a href="#Generation" class="headerlink" title="Generation"></a>Generation</h3>其实就是在学习之前预先进行思考。比如在阅读文本前，先思考一下作者会针对这个topic讲哪些观点。做题的话，即使知道自己可能做不出来，也要在看答案之前自己做一做。学习理科的时候可以在课前根据已经有的知识试着做一下这一章节的题目。<h3 id="Reflection"><a href="#Reflection" class="headerlink" title="Reflection"></a>Reflection</h3>回顾最近的学习内容并思考以下问题：</li><li>哪些是自己做得比较好的？哪些还需要改进和温习？</li><li>这些知识能够联想到哪些别的内容？</li><li>自己还可以做哪些？<h3 id="Calibration"><a href="#Calibration" class="headerlink" title="Calibration"></a>Calibration</h3>寻找一些标准来确认自己对于知识的掌握内容程度。之前已经说过。如果有标准的话就和标准比较，如果没有的话就自己测试，比如课后的习题，自我回顾等等。<h3 id="Mnemonic-Devices"><a href="#Mnemonic-Devices" class="headerlink" title="Mnemonic Devices"></a>Mnemonic Devices</h3>这就比较骚了，只要搜索『记忆方法』就能找出一大堆，这里不赘述了。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;高中的时候，由于被整个大环境洗了脑，我拿出了前所未有的干劲，开始随着全日制高中每一个小时都被安排好的作息，做出一副每时每刻都在好好学习的样子，但我很快就意识到，自己对所谓『知识』的掌握程度并不好，以至于到底学到了什么，我自己也说不出来。虽然隐约地觉得自己的学习方式可能出了些问题，但那时的我更认为自己只是还不够努力，只要没有学到死就没有资格去考虑这个问题，至于那些取得好成绩的同学，我统统将他们纳入天赋异禀的范畴。&lt;/p&gt;
&lt;p&gt;直到这个春假忙里偷闲地看了本叫做『&lt;a href=&quot;https://books.google.com/books/about/Make_It_Stick.html?id=t9JoAwAAQBAJ&amp;amp;source=kp_book_description&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Make It Stick&lt;/a&gt;』的书，自己隐约的猜想才算成了现实——是的，我之前接近二十年的人生中，很多时候的所谓『学习』都是无效的，为什么？因为没有动脑。现在想来，正如高中的我相信自己可以靠一点睡五点半起来取得好成绩一样，其实只是自己感动自己罢了——因为认真地去分析、去记忆很累，因此把时间用来不断地反复理解或记忆表层的内容，然后觉得自己应该掌握了，然后直接跳到下一个知识点。&lt;/p&gt;
&lt;p&gt;这本书里面提到了一个叫做effortful learning的概念，其实这东西没什么可解释的，就是动脑子学的意思，基本上是个学生可能都能明白『真正动脑子学』是什么意思。我先解释一下为什么很多人都做不到effortful learning，然后再直接上方法论，至于effortful learning的益处暂时略去不谈，一些心理学和神经科学的原理我也不解释了。另外，书中针对教育者（父母、老师、培训机构等）也有一些针对性的建议，这里也略去不谈，以下内容主要针对像我这样的（苦逼）学生。&lt;br&gt;
    
    </summary>
    
      <category term="阅读笔记" scheme="http://sheronw.github.io/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>EH Forwarder Bot 2.0保持后台运行（Screen）</title>
    <link href="http://sheronw.github.io/2019/02/22/efbscreen/"/>
    <id>http://sheronw.github.io/2019/02/22/efbscreen/</id>
    <published>2019-02-22T22:41:17.000Z</published>
    <updated>2019-03-03T02:54:33.814Z</updated>
    
    <content type="html"><![CDATA[<p>微信升级到7之后就经常收不到后台推送（不知道问题是出在美国的网络还是我的pixel），但网页版的推送显然是正常的，于是决定时隔一年再次卸载微信，使用efb。<br><del>要是有空顺便把Facebook Messenger也部署了吧</del><br><a href="https://ehforwarderbot.readthedocs.io/en/latest/index.html" target="_blank" rel="external">感兴趣的话可以看一下这个documentation</a><br><a id="more"></a><br>用的是Vultr的VPS，5刀一个月的那个（之前用的是digitalocean，github student package里面有优惠），有点肉疼……<br>安装方法和当初装1.0没什么区别，只不过后台运行的方法和之前不太一样，所以从<a href="https://whitecodes.github.io/2018/02/Eh-Forwarder-Bot-2-0/" target="_blank" rel="external">这里</a>找到了解决方案，记在下面：</p><ol><li>首先要用screen保持后台运行</li><li>将其后台化需要Ctrl+a、Ctrl+d</li><li>再次打开的话需要执行screen -ls命令，然后再screen -r XXXXX</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;微信升级到7之后就经常收不到后台推送（不知道问题是出在美国的网络还是我的pixel），但网页版的推送显然是正常的，于是决定时隔一年再次卸载微信，使用efb。&lt;br&gt;&lt;del&gt;要是有空顺便把Facebook Messenger也部署了吧&lt;/del&gt;&lt;br&gt;&lt;a href=&quot;https://ehforwarderbot.readthedocs.io/en/latest/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;感兴趣的话可以看一下这个documentation&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="实用主义" scheme="http://sheronw.github.io/categories/%E5%AE%9E%E7%94%A8%E4%B8%BB%E4%B9%89/"/>
    
    
  </entry>
  
  <entry>
    <title>浮点数的表示法以及加法乘法</title>
    <link href="http://sheronw.github.io/2019/02/20/float/"/>
    <id>http://sheronw.github.io/2019/02/20/float/</id>
    <published>2019-02-20T18:40:28.000Z</published>
    <updated>2019-02-24T21:16:27.200Z</updated>
    
    <content type="html"><![CDATA[<h2 id="浮点数的表示法"><a href="#浮点数的表示法" class="headerlink" title="浮点数的表示法"></a>浮点数的表示法</h2><p>每一个浮点数都要转换成二进制版本的科学计数法再储存起来（也就是x*2<sup>y</sup>），因此需要存储如下数据：正负号（0正1负），科学计数法的幂（2的次方数），科学计数法的小数部分（用-2进制来表示）。</p><h3 id="十进制转二进制"><a href="#十进制转二进制" class="headerlink" title="十进制转二进制"></a>十进制转二进制</h3><p>把这个数分成小数和整数两种形式。<br>整数直接转二进制然后使用科学计数法。<br>分数部分，每次乘2，取该数的整数部分（要么取不到整数，要么取走1），直到啥都不剩为止。取到的数从左往右写，最前面加0.。</p><a id="more"></a><h3 id="IEEE-Floating-Point-Standard-754标准"><a href="#IEEE-Floating-Point-Standard-754标准" class="headerlink" title="IEEE Floating Point Standard 754标准"></a>IEEE Floating Point Standard 754标准</h3><p>32bits（float）从左往右依次为：</p><ul><li>31: 正负号</li><li>30-23: 8 bits的幂数</li><li>22-0: 23 bits的小数部分（因为科学记数法，所以第一位（小数点左侧）必然是1，就不计算在内了）</li></ul><p>64bits（double）从左往右依次为：</p><ul><li>63：正负号</li><li>62-52：11 bits的幂数</li><li>51-0：52 bits的小数部分</li></ul><h3 id="exponent-bias-method"><a href="#exponent-bias-method" class="headerlink" title="exponent bias method"></a>exponent bias method</h3><p>为了表示负数次幂，转换时在原本的幂数中加一些数字。<br>32位+127，64位+1023<br>这样32位幂的表示范围为-126~127，64为-1022~1023<br>在这里我们没有用two’s complement，原因是这种方法更容易比较两个数的大小。</p><h2 id="浮点数的加法"><a href="#浮点数的加法" class="headerlink" title="浮点数的加法"></a>浮点数的加法</h2><p>首先要把他们对齐，也就是说把两个数字的幂转换成一样的。然后和十进制一样相加减，最后再把得到的结果转换成科学记数法。</p><h2 id="浮点数的乘法"><a href="#浮点数的乘法" class="headerlink" title="浮点数的乘法"></a>浮点数的乘法</h2><p>和加法同理。<br>不过可以在乘之前先判断一下结果的符号，同号为正异号为负。<br>然后相乘（小数部分相乘，幂数相加），最后转回科学记数法。</p><p>不过在实现运算的过程中要注意，储存幂数的时候用的是bias method，而且小数部分中小数点左边的部分并没有实际存储在浮点数中。（血一样的教训）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;浮点数的表示法&quot;&gt;&lt;a href=&quot;#浮点数的表示法&quot; class=&quot;headerlink&quot; title=&quot;浮点数的表示法&quot;&gt;&lt;/a&gt;浮点数的表示法&lt;/h2&gt;&lt;p&gt;每一个浮点数都要转换成二进制版本的科学计数法再储存起来（也就是x*2&lt;sup&gt;y&lt;/sup&gt;），因此需要存储如下数据：正负号（0正1负），科学计数法的幂（2的次方数），科学计数法的小数部分（用-2进制来表示）。&lt;/p&gt;
&lt;h3 id=&quot;十进制转二进制&quot;&gt;&lt;a href=&quot;#十进制转二进制&quot; class=&quot;headerlink&quot; title=&quot;十进制转二进制&quot;&gt;&lt;/a&gt;十进制转二进制&lt;/h3&gt;&lt;p&gt;把这个数分成小数和整数两种形式。&lt;br&gt;整数直接转二进制然后使用科学计数法。&lt;br&gt;分数部分，每次乘2，取该数的整数部分（要么取不到整数，要么取走1），直到啥都不剩为止。取到的数从左往右写，最前面加0.。&lt;/p&gt;
    
    </summary>
    
      <category term="学业相关" scheme="http://sheronw.github.io/categories/%E5%AD%A6%E4%B8%9A%E7%9B%B8%E5%85%B3/"/>
    
    
  </entry>
  
  <entry>
    <title>Belmont Principles</title>
    <link href="http://sheronw.github.io/2019/02/17/Belmont_Principles/"/>
    <id>http://sheronw.github.io/2019/02/17/Belmont_Principles/</id>
    <published>2019-02-17T14:52:52.000Z</published>
    <updated>2019-02-24T21:30:03.877Z</updated>
    
    <content type="html"><![CDATA[<p>Ethical Principles and Guidelines for the Protection of Human<br>Subjects of Research<br>好吧，这很人道主义。<br>三条粗略看完之后，觉得在实际情况中做出相应的权衡还是很难，几乎不太可能全部做到啊hhhh</p><a id="more"></a><h2 id="Respect-for-Persons"><a href="#Respect-for-Persons" class="headerlink" title="Respect for Persons"></a>Respect for Persons</h2><h3 id="acknowledge-autonomy"><a href="#acknowledge-autonomy" class="headerlink" title="acknowledge autonomy"></a>acknowledge autonomy</h3><p>autonomy的人就是有能力考虑自己的目标并行动的人。反正要尊重这帮人的意见和想法，除非他们干了对别人有害的事情，否则不能随意阻止他们的行为。</p><h3 id="protect-those-with-diminished-autonomy"><a href="#protect-those-with-diminished-autonomy" class="headerlink" title="protect those with diminished autonomy"></a>protect those with diminished autonomy</h3><p>对于那些做不到autonomy的人，就需要保护并且帮助他们。</p><h2 id="Beneficence"><a href="#Beneficence" class="headerlink" title="Beneficence"></a>Beneficence</h2><h3 id="do-not-harm"><a href="#do-not-harm" class="headerlink" title="do not harm"></a>do not harm</h3><p>不能伤害他们，也不能让他们有受伤的风险。</p><h3 id="maximize-possible-benefits-and-minimize-possible-harms"><a href="#maximize-possible-benefits-and-minimize-possible-harms" class="headerlink" title="maximize possible benefits and minimize possible harms"></a>maximize possible benefits and minimize possible harms</h3><p>最大化收益，不一定是对实验对象的收益，而是一个群体甚至全人类的那种长期收益。</p><h2 id="Justice"><a href="#Justice" class="headerlink" title="Justice"></a>Justice</h2><h3 id="to-each-person-an-equal-share"><a href="#to-each-person-an-equal-share" class="headerlink" title="to each person an equal share"></a>to each person an equal share</h3><h3 id="to-each-person-according-to-individual-need"><a href="#to-each-person-according-to-individual-need" class="headerlink" title="to each person according to individual need"></a>to each person according to individual need</h3><h3 id="to-each-person-according-to-individual-effort"><a href="#to-each-person-according-to-individual-effort" class="headerlink" title="to each person according to individual effort"></a>to each person according to individual effort</h3><h3 id="to-each-person-according-to-societal-contribution"><a href="#to-each-person-according-to-societal-contribution" class="headerlink" title="to each person according to societal contribution"></a>to each person according to societal contribution</h3><h3 id="to-each-person-according-to-merit"><a href="#to-each-person-according-to-merit" class="headerlink" title="to each person according to merit."></a>to each person according to merit.</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Ethical Principles and Guidelines for the Protection of Human&lt;br&gt;Subjects of Research&lt;br&gt;好吧，这很人道主义。&lt;br&gt;三条粗略看完之后，觉得在实际情况中做出相应的权衡还是很难，几乎不太可能全部做到啊hhhh&lt;/p&gt;
    
    </summary>
    
      <category term="学业相关" scheme="http://sheronw.github.io/categories/%E5%AD%A6%E4%B8%9A%E7%9B%B8%E5%85%B3/"/>
    
    
  </entry>
  
  <entry>
    <title>bit level operators</title>
    <link href="http://sheronw.github.io/2019/02/13/bit_level_operators/"/>
    <id>http://sheronw.github.io/2019/02/13/bit_level_operators/</id>
    <published>2019-02-14T00:40:21.000Z</published>
    <updated>2019-02-24T21:17:12.085Z</updated>
    
    <content type="html"><![CDATA[<h2 id="编程语言中的操作符"><a href="#编程语言中的操作符" class="headerlink" title="编程语言中的操作符"></a>编程语言中的操作符</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><ul><li>&lt;&lt; left shift</li><li>>> signed right shift (filled with sign bits)</li><li>>>> unsigned right shift (filled with 0s)</li><li>&amp; bitwise and</li><li>| bitwise or</li><li>^ bitwise exclusive or</li></ul><a id="more"></a><h3 id="C"><a href="#C" class="headerlink" title="C"></a>C</h3><p>大致与Java相同，只是没有unsigned right shift，具体会怎么shift取决于数据型本身。</p><h2 id="一些用法"><a href="#一些用法" class="headerlink" title="一些用法"></a>一些用法</h2><h3 id="set-bits-to-0"><a href="#set-bits-to-0" class="headerlink" title="set bits to 0"></a>set bits to 0</h3><p>x&amp;0=0<br>x&amp;1=x</p><h3 id="set-bits-to-1"><a href="#set-bits-to-1" class="headerlink" title="set bits to 1"></a>set bits to 1</h3><p>x|0=x<br>x|1=1</p><h3 id="invert-bits"><a href="#invert-bits" class="headerlink" title="invert bits"></a>invert bits</h3><p>x^0=x<br>x^1=!x</p><h2 id="应用……？"><a href="#应用……？" class="headerlink" title="应用……？"></a>应用……？</h2><p>刚刚看到了<a href="https://blog.coca.moe/post/er-jin-zhi-mei-ju" target="_blank" rel="external">这么一道题</a>，发现和当初学离散数学的时候遇到的那个小朋友分饼干的题型有点像，都是二进制的应用，就当是位运算的一个实例放在这里了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;编程语言中的操作符&quot;&gt;&lt;a href=&quot;#编程语言中的操作符&quot; class=&quot;headerlink&quot; title=&quot;编程语言中的操作符&quot;&gt;&lt;/a&gt;编程语言中的操作符&lt;/h2&gt;&lt;h3 id=&quot;Java&quot;&gt;&lt;a href=&quot;#Java&quot; class=&quot;headerlink&quot; title=&quot;Java&quot;&gt;&lt;/a&gt;Java&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&amp;lt;&amp;lt; left shift&lt;/li&gt;
&lt;li&gt;&gt;&gt; signed right shift (filled with sign bits)&lt;/li&gt;
&lt;li&gt;&gt;&gt;&gt; unsigned right shift (filled with 0s)&lt;/li&gt;
&lt;li&gt;&amp;amp; bitwise and&lt;/li&gt;
&lt;li&gt;| bitwise or&lt;/li&gt;
&lt;li&gt;^ bitwise exclusive or&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="学业相关" scheme="http://sheronw.github.io/categories/%E5%AD%A6%E4%B8%9A%E7%9B%B8%E5%85%B3/"/>
    
    
  </entry>
  
  <entry>
    <title>十进制、二进制与十六进制的相互转换，以及Two’s Complement Notation</title>
    <link href="http://sheronw.github.io/2019/02/13/10,2,16&amp;Two&#39;s%20Complement%20Notation/"/>
    <id>http://sheronw.github.io/2019/02/13/10,2,16&amp;Two&#39;s Complement Notation/</id>
    <published>2019-02-13T23:47:37.000Z</published>
    <updated>2019-02-24T21:17:15.497Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二进制转十进制"><a href="#二进制转十进制" class="headerlink" title="二进制转十进制"></a>二进制转十进制</h2><p>很简单，从右往左加，第一位乘以2的零次方，第二位乘以2的一次方，然后以此类推……<br>10101<sub>10</sub>=1*2^4+0*2^3+1*2^2+0*2^1+1*2^0=21<br>还有一种方法是Horner’s Rule，从左往右算，每次把下一位加在这个结果中作为一个整体。<br>10101<sub>10</sub>=(((1*2+0)*2+1)*2+0)*2+1=21</p><h2 id="十进制转二进制"><a href="#十进制转二进制" class="headerlink" title="十进制转二进制"></a>十进制转二进制</h2><p>不断地除以二，直到除不动了为止，每一步得到的余数倒过来就是所求的二进制。</p><ul><li><strong>10</strong>/2=5 …0</li><li>5/2=2 … 1</li><li>2/2=1 … 0</li><li>1/2=0 … 1</li></ul><p>所以10的二进制为1010<br>当然，如果不想最后再颠倒一遍的话，可以算的时候从下往上写XD<br><a id="more"></a></p><h2 id="十六进制转二进制"><a href="#十六进制转二进制" class="headerlink" title="十六进制转二进制"></a>十六进制转二进制</h2><p>十六进制的每一位都能转换成一个四位的二进制，然后把它们拼起来就好，其实还有一个转换表，但算起来也不麻烦，我觉得不背也行。</p><h2 id="二进制转十六进制"><a href="#二进制转十六进制" class="headerlink" title="二进制转十六进制"></a>二进制转十六进制</h2><p>和上面一个道理，每四位二进制都能转换成一位十六进制，如果最后一组不足四位填上几个零就好。</p><h2 id="十六进制转十进制"><a href="#十六进制转十进制" class="headerlink" title="十六进制转十进制"></a>十六进制转十进制</h2><p>和二进制转十进制一个道理，只不过把2换成16了而已。</p><h2 id="十进制转十六进制"><a href="#十进制转十六进制" class="headerlink" title="十进制转十六进制"></a>十进制转十六进制</h2><p>同上，和二进制一样，只不过不断除以16。</p><h2 id="Two’s-Complement"><a href="#Two’s-Complement" class="headerlink" title="Two’s Complement"></a>Two’s Complement</h2><p>这是一种用二进制表达整数（包括正负）的一种方法。<br>首先，从最左边的那一位可以看出这个数字的正负——0为正，1为负。<br>如果是正数的话，和之前讲到的传统二进制表达是相同的。<br>如果是负数的话，想要知道它的具体值，我们需要将Two’s Complement转换成它的相反数（也就是说这个数字的整数版本）。<br>转换成相反数的算法如下（同时适用与正数和负数）：</p><ul><li>将每一位的数字颠倒（颠倒指的是，1换成0，0换成1）</li><li>在颠倒之后的基础上再+1</li></ul><p>比如这里有个我瞎编的32bits的数字：<br>1010 0100 0100 1111 1010 1100 0101 0000<br>第一位是1，所以这个数是小于零的<br>首先我们要把它变成这样的：<br>0101 1011 1011 0000 0101 0011 1010 1111<br>然后再+1就变成了这样：<br>0101 1011 1011 0000 0101 0011 1011 0000<br>这个数就是最前面瞎编的那个数的相反数</p><p>哦对了，因为32bits的二进制写起来太长了，所以经常会用十六进制来表示。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;二进制转十进制&quot;&gt;&lt;a href=&quot;#二进制转十进制&quot; class=&quot;headerlink&quot; title=&quot;二进制转十进制&quot;&gt;&lt;/a&gt;二进制转十进制&lt;/h2&gt;&lt;p&gt;很简单，从右往左加，第一位乘以2的零次方，第二位乘以2的一次方，然后以此类推……&lt;br&gt;10101&lt;sub&gt;10&lt;/sub&gt;=1*2^4+0*2^3+1*2^2+0*2^1+1*2^0=21&lt;br&gt;还有一种方法是Horner’s Rule，从左往右算，每次把下一位加在这个结果中作为一个整体。&lt;br&gt;10101&lt;sub&gt;10&lt;/sub&gt;=(((1*2+0)*2+1)*2+0)*2+1=21&lt;/p&gt;
&lt;h2 id=&quot;十进制转二进制&quot;&gt;&lt;a href=&quot;#十进制转二进制&quot; class=&quot;headerlink&quot; title=&quot;十进制转二进制&quot;&gt;&lt;/a&gt;十进制转二进制&lt;/h2&gt;&lt;p&gt;不断地除以二，直到除不动了为止，每一步得到的余数倒过来就是所求的二进制。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;10&lt;/strong&gt;/2=5 …0&lt;/li&gt;
&lt;li&gt;5/2=2 … 1&lt;/li&gt;
&lt;li&gt;2/2=1 … 0&lt;/li&gt;
&lt;li&gt;1/2=0 … 1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以10的二进制为1010&lt;br&gt;当然，如果不想最后再颠倒一遍的话，可以算的时候从下往上写XD&lt;br&gt;
    
    </summary>
    
      <category term="学业相关" scheme="http://sheronw.github.io/categories/%E5%AD%A6%E4%B8%9A%E7%9B%B8%E5%85%B3/"/>
    
    
  </entry>
  
  <entry>
    <title>写在最后，或者最前 - 简单粗暴数据结构（13）</title>
    <link href="http://sheronw.github.io/2019/01/17/ds-finally/"/>
    <id>http://sheronw.github.io/2019/01/17/ds-finally/</id>
    <published>2019-01-18T00:29:37.000Z</published>
    <updated>2019-01-18T00:37:40.439Z</updated>
    
    <content type="html"><![CDATA[<p>  虽然成绩看着没啥大毛病，但是我知道我数据结构学得十分垃圾。本来复习数构这个计划会被无限期拖延下去的，直到鲸鱼小姐姐作为一位文科生想要勇敢地尝试一下这门传说中『劝退好多人major in cs』的data structure。她跟我说哎呀要不这个冬天我稍微预习一下吧，我说好啊那我给你粗略地写点知识点，再用纯正的大白话稍微解释一下。<br><a id="more"></a></p><p>  然后在她的微信远程监督下，直到今天我算是把当初学过的知识点都过了一遍。其实当初很多觉得学得恶心得不行的东西，现在看来其实也就那样。当然我不是说这些文章好到能够当教程了——我真的不敢，这玩意儿顶多当笔记我自己看看，或者分享给小圈子里的人。不过也就因为这样，我可能会在今后的很长一段时间里继续加工这些文章，添加一点别的东西——这就是为什么我在标题里写『或者最前』的意思，这只是开始。</p><p>以下是目录：</p><ul><li><a href="https://sheronw.github.io/2019/01/03/ds-list/">The List Interface</a></li></ul><ul><li><a href="https://sheronw.github.io/2019/01/04/ds-stackandqueue/">Stack &amp; Queue</a></li></ul><ul><li><a href="https://sheronw.github.io/2019/01/05/ds-algs_analysis/">Algorithm Analysis</a></li></ul><ul><li><a href="https://sheronw.github.io/2019/01/06/ds-arithmetic_expression/">Arithmetic Expression</a></li></ul><ul><li><p>Tree</p><ul><li><p><a href="https://sheronw.github.io/2019/01/07/ds-tree1/">Basic &amp; Binary Tree</a></p></li><li><p><a href="https://sheronw.github.io/2019/01/09/ds-tree2/">Binary Search Tree &amp; AVL Tree &amp; Red Black Tree</a></p></li><li><p><a href="https://sheronw.github.io/2019/01/10/ds-tree3/">B Tree &amp; Trie &amp; Huffman Tree</a></p></li></ul></li></ul><ul><li><a href="https://sheronw.github.io/2019/01/11/ds-pq/">Priority Queue</a></li></ul><ul><li><a href="https://sheronw.github.io/2019/01/12/ds-hashing/">Hashing</a></li></ul><ul><li><p>Graph</p><ul><li><p><a href="https://sheronw.github.io/2019/01/12/ds-hashing/">Basic &amp; Representation</a></p></li><li><p><a href="https://sheronw.github.io/2019/01/12/ds-hashing/">Search &amp; Shortest Paths</a></p></li><li><p><a href="https://sheronw.github.io/2019/01/12/ds-hashing/">Minimum Spanning Tree</a></p></li></ul></li><li><p>Sorting</p><p>  这一篇我根本没写。有一个<a href="https://github.com/hustcc/JS-Sorting-Algorithm" target="_blank" rel="external">现成的gitbook</a>我觉得写得就挺好的，只不过我们那节课没有学希尔排序、计数排序和桶排序，空间复杂度也暂时没讲。</p></li></ul><p>因为写得挺匆忙的，外加自身水平也不够，要是有任何谬误跪求各位读者老爷们赏个脸指出来……</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  虽然成绩看着没啥大毛病，但是我知道我数据结构学得十分垃圾。本来复习数构这个计划会被无限期拖延下去的，直到鲸鱼小姐姐作为一位文科生想要勇敢地尝试一下这门传说中『劝退好多人major in cs』的data structure。她跟我说哎呀要不这个冬天我稍微预习一下吧，我说好啊那我给你粗略地写点知识点，再用纯正的大白话稍微解释一下。&lt;br&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Graph part 3 - 简单粗暴数据结构（12）</title>
    <link href="http://sheronw.github.io/2019/01/15/ds-graph3/"/>
    <id>http://sheronw.github.io/2019/01/15/ds-graph3/</id>
    <published>2019-01-16T00:58:31.000Z</published>
    <updated>2019-01-16T01:01:20.914Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Minimum-Spanning-Tree"><a href="#Minimum-Spanning-Tree" class="headerlink" title="Minimum Spanning Tree"></a>Minimum Spanning Tree</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>我不知道该怎么描述，总的来说，给一个图，选出来一些互相相连但不成环（connected but acyclic）的edge，使得这些edge的总和最小，并且每一个点都能通过这个集合走到另外任意一个点。”connect network at min cost”<br><a id="more"></a></p><h3 id="Prim’s-Algorithm"><a href="#Prim’s-Algorithm" class="headerlink" title="Prim’s Algorithm"></a>Prim’s Algorithm</h3><p>这个算法把图里面所有的点分为两部分：已经连起来的和还没有连起来的。我们先从起点r开始，这样r自己属于连起来的，别的点都是还没连起来的。因为是minimum，所以我们又用到了『贪心』的思想，所以要找到一个和r相连的值最小的edge，用它把r和另外一个点连起来，这样这个点也被加到了『连起来的』这个集合里面了，然后我们在找一个能和这个集合搭界的最小的edge……直到所有的点都被连起来了为止。</p><p><img src="https://i.loli.net/2019/01/16/5c3e7d51808f3.png" alt="enter image description here"></p><pre><code>S={r}T={}while S != V(the set of all vertices):    find the cheapest edge crossing S and V/S(就是所有点的集合里面除了S之外的部分), let it be e    add e to T    vertex=end of e not in S    add vertex to Sreturn e</code></pre><p>首先我们每次都要和一个新的点相连，图里一共|V|个点，所以while loop要运行|V|次吧。最坏情况下所有的edge都和这个点相连，所以循环里面最坏要运行|E|次吧。所以时间复杂度是O(|V||E|)。</p><h3 id="Kruskal’s-algorithm"><a href="#Kruskal’s-algorithm" class="headerlink" title="Kruskal’s algorithm"></a>Kruskal’s algorithm</h3><p>如果上一个算法是找一棵大树，那么这个算法是要找一片森林，然后把它们拼成一棵大树……<br>首先先将给所有edge的值排个序，然后一个一个从最小的开始往上加——只要加上这个edge图里面不会出现任何圈，那么就可以放心地加上去……直到我们发现所有的vertices都被连起来了为止。<br>（我画了一下图，结果发现和上面那个图一模一样？）</p><pre><code>sort all edges by weightT={}for each edge e(in sorted order):    if adding e doesn&apos;t create a cycle:        add e to Treturn T</code></pre><p>看一下时间复杂度。开头给edge排序可以就用之前的任何一种排序算法，最快的是O(|E|log|E|)。循环一共是O(|E|)次。检查是否有cycle需要用到广度优先搜索，就是O(|V|+|E|)。这么分析的话时间复杂度应该是O(|E|log|E|+|E|(|V|+|E|))=O(|E|<sup>2</sup>)。<br>不过有奇技淫巧可以把这个的时间复杂度降到O(|E|log|V|)<br>，具体怎么操作的我也不太清楚……</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Minimum-Spanning-Tree&quot;&gt;&lt;a href=&quot;#Minimum-Spanning-Tree&quot; class=&quot;headerlink&quot; title=&quot;Minimum Spanning Tree&quot;&gt;&lt;/a&gt;Minimum Spanning Tree&lt;/h2&gt;&lt;h3 id=&quot;Definition&quot;&gt;&lt;a href=&quot;#Definition&quot; class=&quot;headerlink&quot; title=&quot;Definition&quot;&gt;&lt;/a&gt;Definition&lt;/h3&gt;&lt;p&gt;我不知道该怎么描述，总的来说，给一个图，选出来一些互相相连但不成环（connected but acyclic）的edge，使得这些edge的总和最小，并且每一个点都能通过这个集合走到另外任意一个点。”connect network at min cost”&lt;br&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Graph part 2 - 简单粗暴数据结构（11）</title>
    <link href="http://sheronw.github.io/2019/01/14/ds-graph2/"/>
    <id>http://sheronw.github.io/2019/01/14/ds-graph2/</id>
    <published>2019-01-15T01:57:54.000Z</published>
    <updated>2019-01-15T01:59:39.274Z</updated>
    
    <content type="html"><![CDATA[<p>这一篇文章就是各种奇怪的算法了……但考试中给一个图能画出来算法每一步得到的结果就ok，实在不理解的话，死记硬背其实也是可以的hhh</p><h2 id="Search"><a href="#Search" class="headerlink" title="Search"></a>Search</h2><p>以下算法针对indirect graph，用来遍历图中每个点。</p><h3 id="Breadth-First-Search-BFS"><a href="#Breadth-First-Search-BFS" class="headerlink" title="Breadth First Search(BFS)"></a>Breadth First Search(BFS)</h3><p>广度优先搜索。如名字所示，就是把当前所在的vertex周围的vertex都搜索一遍，然后<strong>依次</strong>对它周围的vertex都执行相同的这个操作……<br>咦，好像可以用队列呀？只要检查完它周围的vertex，然后把它们全加进队列里面，然后从队列里面取出下一个就可以咯？<br>当然，秉着效率优先的原则，我们要把已经检查过了的vertex进行标记，这样就不用再搜一遍了。<br><a id="more"></a></p><pre><code>将开始搜索的vertex（就记作s吧）放入队列q中当队列q不为空时：    dequeue出来一个vertex u    检查是否是我们要找的，是的话就return该vertex    将u进行标记    for u的所有邻居 v：        如果v没有标记：            将v加入队列qreturn『无结果』</code></pre><p>时间复杂度：O(V+E)<br>首先所有的vertex都要被enqueue和dequeue一次，所以是O(V)；其次对每个u来说，所有的邻居都要被扫描一遍检查是否有标记（也就是说扫描一遍和u有关系的所有edge），这样每个edge都被扫描了两遍（因为它和两个vertex有关系），所以是O(E)。</p><p><a href="https://blog.csdn.net/raphealguo/article/details/7523411" target="_blank" rel="external">可以看这一篇</a></p><h3 id="Depth-First-Search-DFS"><a href="#Depth-First-Search-DFS" class="headerlink" title="Depth First Search(DFS)"></a>Depth First Search(DFS)</h3><p>深度优先搜索。就是一条路走到黑，走不下去了就退到上一个节点，再换另一条路。<br>……退回到上一个节点？我们可以用递归或者是栈。<br>stack的话和广度搜索有点相似：</p><pre><code>将起点s标记，放进栈stack中当stack不为空时：    peek最上面的元素u（只是peek，不拿出来）    检查是否u是我们想要的，是的话就return它    在与它相邻的vertices中，看看还有没有没被标记的    要是有的话，找一个没被标记的v，将其标记并放到栈里面    没有的话，就把u从栈里面拿出来return 『无结果』</code></pre><p>递归：</p><pre><code>dfs(V,E,u):    将u进行标记    如果就是我们要找的，结束搜索直接return    for u所有的邻居v：        如果v没有被标记：            dfs(V,E,v)dfs(V,E,起点s)</code></pre><p>时间复杂度和广度优先搜索一样，也是一个vertex都会至少检查一次，每个edge都会检查两次，也是O(V+E)</p><h2 id="Shortest-Paths"><a href="#Shortest-Paths" class="headerlink" title="Shortest Paths"></a>Shortest Paths</h2><p>以下算法用于weighted graph寻找图中两点间最短路径。</p><h3 id="Dijkstra’s-Algorithm"><a href="#Dijkstra’s-Algorithm" class="headerlink" title="Dijkstra’s Algorithm"></a>Dijkstra’s Algorithm</h3><p>这个名字看起来挺奇怪，其实那个j好像不发音，是个荷兰的计算机科学家的姓。这个人名言超级多，忘了听谁说的被誉为是计算机科学界的米兰昆德拉……<br>跑题了，这个算法利用一个表<strong>d</strong>来记录从出发点<strong>s</strong>到图中每一个点的最短距离（初始值是无穷大），然后不断更新它。<br>为了能够找到确切的路径，我们又准备了另外一个表<strong>prev</strong>（初始值为空），用来存储路径中该点前面的那个点，当然也要不断更新它，这样就可以从我们找到的终点一路开倒车找回s了。<br>那么如何不断更新呢？把所有的点都放在一个set里面，然后每次拿出来一个距离最小的（可以用priority queue？）（其实这里用到了一种叫做『贪心』的策略，即既然想要最短路径，那就从最短的开始下手）。<br>给定任意一点u和它的某个邻居v，如何判定我们找到了新的最小距离呢？如果到u的最小距离加上u与v之间的距离竟然小于到v的最小距离，那么就说明经过u到v距离会更短，那么我们就要把到v的最小距离改成之前那个了……</p><pre><code>for all vertices v in graph G: // 初始化    d[v]=infinity    prev[v]=NULLd[s]=0 // 起点到它本身的距离为零while 存在未标记的点:    u=未标记的点中有最小d[u]的那个    for all neighbors v of u:        if d[u]+(u,v)&lt;d[v]:            d[v]=d[u]+(u,v)            prev[v]=u    将u进行标记</code></pre><p>来分析一下这个的时间复杂度，while循环里面包着的for循环有点熟悉，往上一翻发现和广度优先搜索如出一辙，所以这一块儿应该是O(E)。剩下的就是while里面包着的找最小d[u]的那个了，之前我们说过可以用priority queue，这个的时间复杂度是O(logn)，剩下的部分是和点（vertices）有关的，因此是O(VlogV)。加起来总的时间复杂度应该是O(VlogV)。</p><p>那么输出完整路径的算法为：</p><pre><code>v=我们要找的终点while prev[v]!=s:    print v    v=prev[v]print s</code></pre><p>悄悄地说一句，这是我们当初期末考试中唯一一个真正考了的关于graph的算法……hhh</p><h3 id="Floyd’s-Algorithms"><a href="#Floyd’s-Algorithms" class="headerlink" title="Floyd’s Algorithms"></a>Floyd’s Algorithms</h3><p>dijkstra 的算法虽然快，但有一个问题：当weighted graph中有值为负的edge的时候就用不了了（dijkstra的『贪心』找最短距离的邻居这个策略就行不通了，如果有负edge的话，经过它那里到邻居的距离可能比它的距离还短）。<br>Floyd呢，运用了『动态规划』的算法思想，如果没记错的话<strong>不管是考试还是lab都不太可能会出现，看不懂也没关系</strong>……<br>动态规划比较浅显的解释就是这样：准备一个表，然后开始填表，有一些值要事先填好，每一个需要填的值都与已经填好的某些值有固定关系（类似递归）。<br>之前说到，已经不能用找邻居的方式来解决这个问题了，但我们可以列一张表，把任意两点之间的最短距离都列出来。<br>和之前的adjacency matrix一样，我们需要一个二维数组来记录两点间最小距离（就叫这张表是memo[|V|][|V|]吧）。<br>首先把base case填好。为了便于更新最小值，把所有值都初始化为无穷大。每一点和自己的距离目前是0。任意两个edge之间的距离，我们先初始化为edge的值本身。<br>然后我们来找到填表的关系。因为可能会出现负值，所以不能像之前那样只走一遍了。对于这个图中的每一个点k，我们都要考虑是否有可能有<strong>任何两点之间的最短距离(i,j)</strong>会使用(1…k)这些点（就是将所有点都排一下序）。所以对每个点k来说我们都要从头到尾重新把这个表再填一下，看看会不会有更小的值。如果这个最小距离和k根本没关系的话，那么使用(1…k)这些点和使用(1…k-1)这些点的结果是一样的。如果有关系的话，那么最小距离就可以分成两半——使用从(1…k-1)这些点，从i到k的距离加上从k到j的距离。</p><pre><code>momo[][]=new int[V][V]for i in range (1,V):    for j in range (1,V):        if i==j, memo[i][j]=0        else, memo[i][j]=infinityfor edges (u,v) in G:    memo[u][v]=d(u,v)for k from 1 to V:    for i from 1 to V:        for j from 1 to V:            if memo[i][j]&gt;memo[i][k]+memo[k][j]:                memo[i][j]=memo[i][k]+memo[k][j]</code></pre><p>时间复杂度倒是一看便知，三个for循环，O(V<sup>3</sup>)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一篇文章就是各种奇怪的算法了……但考试中给一个图能画出来算法每一步得到的结果就ok，实在不理解的话，死记硬背其实也是可以的hhh&lt;/p&gt;
&lt;h2 id=&quot;Search&quot;&gt;&lt;a href=&quot;#Search&quot; class=&quot;headerlink&quot; title=&quot;Search&quot;&gt;&lt;/a&gt;Search&lt;/h2&gt;&lt;p&gt;以下算法针对indirect graph，用来遍历图中每个点。&lt;/p&gt;
&lt;h3 id=&quot;Breadth-First-Search-BFS&quot;&gt;&lt;a href=&quot;#Breadth-First-Search-BFS&quot; class=&quot;headerlink&quot; title=&quot;Breadth First Search(BFS)&quot;&gt;&lt;/a&gt;Breadth First Search(BFS)&lt;/h3&gt;&lt;p&gt;广度优先搜索。如名字所示，就是把当前所在的vertex周围的vertex都搜索一遍，然后&lt;strong&gt;依次&lt;/strong&gt;对它周围的vertex都执行相同的这个操作……&lt;br&gt;咦，好像可以用队列呀？只要检查完它周围的vertex，然后把它们全加进队列里面，然后从队列里面取出下一个就可以咯？&lt;br&gt;当然，秉着效率优先的原则，我们要把已经检查过了的vertex进行标记，这样就不用再搜一遍了。&lt;br&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Graph part 1 - 简单粗暴数据结构（10）</title>
    <link href="http://sheronw.github.io/2019/01/13/ds-graph1/"/>
    <id>http://sheronw.github.io/2019/01/13/ds-graph1/</id>
    <published>2019-01-13T18:40:08.000Z</published>
    <updated>2019-01-13T19:14:43.636Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Basic-Terminology"><a href="#Basic-Terminology" class="headerlink" title="Basic Terminology"></a>Basic Terminology</h2><p>这学期最后一个数据结构是图。简单地来说就是『由线连起来的点』，由Vertex（点）和Edge（线）组成。G=(V,E)<br>下面的很多定义都是从图论（数学）里面拿来用的hhh</p><h3 id="direct-amp-indirect"><a href="#direct-amp-indirect" class="headerlink" title="direct &amp; indirect"></a>direct &amp; indirect</h3><p>根据edge是否有方向（带箭头），graph可以分成direct graph（digraph）和indirect graph（没有方向的）。<br>如果是direct graph，那么edge可以用两个<strong>有序的</strong>vertices来表示。<br><a id="more"></a></p><h3 id="dense-amp-sparse"><a href="#dense-amp-sparse" class="headerlink" title="dense &amp; sparse"></a>dense &amp; sparse</h3><p>根据edge的数量多少，graph又可以分成dense graph和sparse graph。<br>如果这个图比较dense，那么对每一个vertex来说，都几乎和剩下所有的edge相连，那么E=O(V<sup>2</sup>)。<br>如果这个图比较sparse，edge的数量肯定是小于O(V<sup>2</sup>)的。<br>一般来说，sparse graph更适合用adjacency list来represent（见后面）。</p><p>cycle是一条从一个vertex出发，又回到它这里的一段路径。</p><h3 id="weighted-amp-unweighted"><a href="#weighted-amp-unweighted" class="headerlink" title="weighted &amp; unweighted"></a>weighted &amp; unweighted</h3><p>weighted graph其实就是在edge上标了数值。一个实际应用的例子就是走不同edge所需要的旅行成本。</p><h2 id="Representation-Methods"><a href="#Representation-Methods" class="headerlink" title="Representation Methods"></a>Representation Methods</h2><p><img src="https://i.loli.net/2019/01/14/5c3b845879e26.png" alt="enter image description here"></p><h3 id="Adjacency-Matrix"><a href="#Adjacency-Matrix" class="headerlink" title="Adjacency Matrix"></a>Adjacency Matrix</h3><p>适用于dense graph。<br>简单来讲就是搞一个矩阵，横纵座标分别代表一个vertex，如果这两个vertices之间有edge，这一格的值就为1，否则为0。<br>如果是directed graph的话，可以规定横或纵中的一个为起始vertex。<br>如果是weighted graph的话，把1换成值就可以了。</p><h3 id="Adjacency-Lists"><a href="#Adjacency-Lists" class="headerlink" title="Adjacency Lists"></a>Adjacency Lists</h3><p>适用于sparse graph。<br>简单地说就是每一个vertex都有一个相应的linked-list，记录了所有与它相连的vertices。<br>如果是directed graph的话，就只记录以它为起点的edge对应的vertices。<br>如果是weighted graph的话，linked-list中再增加一项edge的值。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Basic-Terminology&quot;&gt;&lt;a href=&quot;#Basic-Terminology&quot; class=&quot;headerlink&quot; title=&quot;Basic Terminology&quot;&gt;&lt;/a&gt;Basic Terminology&lt;/h2&gt;&lt;p&gt;这学期最后一个数据结构是图。简单地来说就是『由线连起来的点』，由Vertex（点）和Edge（线）组成。G=(V,E)&lt;br&gt;下面的很多定义都是从图论（数学）里面拿来用的hhh&lt;/p&gt;
&lt;h3 id=&quot;direct-amp-indirect&quot;&gt;&lt;a href=&quot;#direct-amp-indirect&quot; class=&quot;headerlink&quot; title=&quot;direct &amp;amp; indirect&quot;&gt;&lt;/a&gt;direct &amp;amp; indirect&lt;/h3&gt;&lt;p&gt;根据edge是否有方向（带箭头），graph可以分成direct graph（digraph）和indirect graph（没有方向的）。&lt;br&gt;如果是direct graph，那么edge可以用两个&lt;strong&gt;有序的&lt;/strong&gt;vertices来表示。&lt;br&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Hashing - 简单粗暴数据结构（9）</title>
    <link href="http://sheronw.github.io/2019/01/12/ds-hashing/"/>
    <id>http://sheronw.github.io/2019/01/12/ds-hashing/</id>
    <published>2019-01-12T18:39:54.000Z</published>
    <updated>2019-01-12T18:41:11.602Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h2><p>之前在array里面查找一个东西，要么线性搜索，要么把这个array排好再搜……<br>hashing就是一种简单粗暴放东西的方法，它用一个hash function，放东西的时候把这个东西的key转换成index，值放在相应的格子里，这样下次搜索这个key的时候就可以秒搜了。</p><p><img src="https://i.loli.net/2019/01/13/5c3a2aaf801be.png" alt="enter image description here"></p><a id="more"></a><h2 id="Hash-Function-Design"><a href="#Hash-Function-Design" class="headerlink" title="Hash Function Design"></a>Hash Function Design</h2><p>就是把keys转换成整数（index）的函数啦，Java好像有现成的method可以用。<br>如果keys都是整数，而且整数都不算大的话，f(key)=key。<br>一个好的hash function，当然是要做到『均匀』——首先，不能黏在一起，比如尽可能降低不同的key值指向同一个hashing值的情况（也就是说collision）。其次，也不能距离太远，array不能搞得太大，至少要控制在空间复杂度小于O(2<sup>n</sup>)吧。</p><h3 id="Division-Method"><a href="#Division-Method" class="headerlink" title="Division Method"></a>Division Method</h3><p>现在最常用的方法。<br>假设key值已经转换成整数了，hash(key)=key%table size<br>为了减少collision，比较适合做table size的数：prime numbers或者是numbers without small prime factors<br>（power of 2 不是一个好的table size，太容易撞了）</p><h3 id="MAD"><a href="#MAD" class="headerlink" title="MAD"></a>MAD</h3><p>是multiply，add，divide的缩写。<br>hash(key)=(a*key+b)%table size<br>上面的加强版。</p><p>……我能想起来的只有这么多了，上课看下笔记吧。</p><h2 id="Collision-Handing"><a href="#Collision-Handing" class="headerlink" title="Collision Handing"></a>Collision Handing</h2><p>当然，虽然理论上说可以秒搜，但实际上经常是达不到这个情况的——万一正好两个不同key的hash值相等呢？所以我们就要处理这些重复的值。</p><h3 id="Open-Addressing"><a href="#Open-Addressing" class="headerlink" title="Open Addressing"></a>Open Addressing</h3><h4 id="Linear-Probing"><a href="#Linear-Probing" class="headerlink" title="Linear Probing"></a>Linear Probing</h4><p>最简单粗暴的解决办法。要是hash对应的格子已经满了，就放到下一个，这样以此类推直到找到空位。<br>搜索的时候也是，如果这个格子的key值和想要搜的key不相等，就搜下一个，以此类推。<br>缺点是，最坏情况下你可能要把整个表都搜一遍，也就是O(n)。</p><h4 id="Double-Hashing"><a href="#Double-Hashing" class="headerlink" title="Double Hashing"></a>Double Hashing</h4><p>其实也很简单粗暴，准备两个hash function，第一个撞了就换第二个，第二个还撞就用上面那个方法……<br>类似地，还有一种方法叫做rehashing，就是准备i个不同的hash function……（也不是说这i个函数完全不一样，可以只是稍微改动一下系数什么的）</p><h3 id="Separate-Chaining"><a href="#Separate-Chaining" class="headerlink" title="Separate Chaining"></a>Separate Chaining</h3><p>可以说是表中表了。array中的每一个格子里面都存放一个linked list，要是有重复了就把新加进来的key和value存放在linked list里面就好啦。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Basic-Concepts&quot;&gt;&lt;a href=&quot;#Basic-Concepts&quot; class=&quot;headerlink&quot; title=&quot;Basic Concepts&quot;&gt;&lt;/a&gt;Basic Concepts&lt;/h2&gt;&lt;p&gt;之前在array里面查找一个东西，要么线性搜索，要么把这个array排好再搜……&lt;br&gt;hashing就是一种简单粗暴放东西的方法，它用一个hash function，放东西的时候把这个东西的key转换成index，值放在相应的格子里，这样下次搜索这个key的时候就可以秒搜了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/01/13/5c3a2aaf801be.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Priority Queue - 简单粗暴数据结构（8）</title>
    <link href="http://sheronw.github.io/2019/01/11/ds-pq/"/>
    <id>http://sheronw.github.io/2019/01/11/ds-pq/</id>
    <published>2019-01-11T18:45:37.000Z</published>
    <updated>2019-01-11T18:46:39.722Z</updated>
    
    <content type="html"><![CDATA[<p>Priority Queue（优先队列）就是一个Queue，不过每次添加进新的元素都会将queue里面所有东西都按照优先级排一下顺序，有最高优先级的在最前面。</p><h2 id="Basic-Operations"><a href="#Basic-Operations" class="headerlink" title="Basic Operations"></a>Basic Operations</h2><p>和queue一样嘛，enqueue，dequeue，peek<br>当然和queue不一样的是，当你dequeue或者peek的时候，出来的那个元素肯定是优先级最高的（比如说，最大的元素，或者最小的元素）<br><a id="more"></a></p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p>enqueue就是把元素加到list中，O(1)<br>dequeue或者是peek的话要找出优先级最高的，因此要把整个list遍历一遍，所以就是O(n)<br>当然也可以反过来，每次enqueue的时候就把这个元素放在正确的位置上，这样index为零的格子里面就是优先级最高的了，enqueue变成了O(n)，但dequeue和peek都是O(1)<br>但这种implementation显然有点慢，一般来说我们都用heap。</p><h3 id="Heap"><a href="#Heap" class="headerlink" title="Heap"></a>Heap</h3><h4 id="什么是Heap？"><a href="#什么是Heap？" class="headerlink" title="什么是Heap？"></a>什么是Heap？</h4><p>heap也是一种binary tree。和binary  search tree不同的是，爸爸总是大于等于（或者小于等于）两个儿子，两个儿子之间的大小关系并没有规定。爸爸大于等于俩儿子的heap叫max heap，反之叫min heap。</p><h4 id="enqueue"><a href="#enqueue" class="headerlink" title="enqueue"></a>enqueue</h4><p>其实也就是在heap中插入一个元素。<br>方法是，将新加进的元素放在底层最后面，检查它和爸爸是否符合原则，如果不符合就和爸爸交换，直到满足条件（或者它自己成为了root）为止。这种方法叫做sift up。<br>可以看出这个方法和树的层数有关，因此是O(logn)。</p><h4 id="peek"><a href="#peek" class="headerlink" title="peek"></a>peek</h4><p>这个简单，直接return root的值就好，O(1)。</p><h4 id="dequeue"><a href="#dequeue" class="headerlink" title="dequeue"></a>dequeue</h4><p>其实就是在heap里面删除最上面的那个元素。<br>方法是，把底层最后一个元素拿出来放在要删除的这个元素的空缺里，然后检查它的儿子是否满足原则，不满足就交换，直到满足条件（或者它再次回到最底层）为止。这种方法叫做sift down。<br>可以看出这个方法和树的层数有关，因此是O(logn)。</p><p><img src="https://i.loli.net/2019/01/12/5c38e41add166.png" alt="enter image description here"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Priority Queue（优先队列）就是一个Queue，不过每次添加进新的元素都会将queue里面所有东西都按照优先级排一下顺序，有最高优先级的在最前面。&lt;/p&gt;
&lt;h2 id=&quot;Basic-Operations&quot;&gt;&lt;a href=&quot;#Basic-Operations&quot; class=&quot;headerlink&quot; title=&quot;Basic Operations&quot;&gt;&lt;/a&gt;Basic Operations&lt;/h2&gt;&lt;p&gt;和queue一样嘛，enqueue，dequeue，peek&lt;br&gt;当然和queue不一样的是，当你dequeue或者peek的时候，出来的那个元素肯定是优先级最高的（比如说，最大的元素，或者最小的元素）&lt;br&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Tree part 3 - 简单粗暴数据结构（7）</title>
    <link href="http://sheronw.github.io/2019/01/10/ds-tree3/"/>
    <id>http://sheronw.github.io/2019/01/10/ds-tree3/</id>
    <published>2019-01-11T01:01:35.000Z</published>
    <updated>2019-01-11T01:09:15.414Z</updated>
    
    <content type="html"><![CDATA[<p>这一篇文章讲一下关于树的几个变种，lab里面并没有相关的内容，考试虽然也考但也不是重点。</p><h2 id="B-Trees-amp-2-3-Trees"><a href="#B-Trees-amp-2-3-Trees" class="headerlink" title="B-Trees &amp; 2-3 Trees"></a>B-Trees &amp; 2-3 Trees</h2><p>在最前面放一张凡凡制作的表情包：</p><p><img src="https://i.loli.net/2019/01/11/5c378b209ed47.jpg" style="zoom:50%"></p><p>逼数，哦不，B-Tree是这样的，它的一个node里面可以存放好几个变量（可以用linked list来实现），也有不止一个儿子。这样它的层数比其他树都小，搜索起来也会更快。<br>因为一个node里面可以放不止一个变量，所以对于每个逼数，我们都规定一个branching factor t，代表最多能有几个儿子。</p><p>B-Tree的特点：</p><ol><li>Every path from the root to a leaf has the same length（层高是统一的）</li><li>If a node has  t  children, it contains  t−1  keys.（keys就是这个node里面的变量数）</li><li>Every node (except the root) is at least half full.（每个node里面的变量数最少是n/2）</li><li>The elements stored in a given subtree all have keys that are between the keys in the parent node on either side of the subtree pointer. (This generalizes the BST invariant.) </li><li>The root has at least two children if it is not a leaf.</li></ol><a id="more"></a><p><img src="https://i.loli.net/2019/01/11/5c37da39c6c43.png" style="zoom:50%"><br>因为是BST的衍生，所以搜索和遍历都和它大同小异。</p><h3 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h3><p>比较理想一点的状况是，在原来的树里，正好就有适合它的一个空位（因为每一个node不一定都是满的），这样直接插进去就好了。但有的时候，属于这个node的范围里面正好满了……<br>解决办法就是，把这个node中间的那个元素取出来，放在他爸爸那里，然后把已经满了的node分成两个半满的node，连在相应的位置上（要是爸爸满了就再往上推）。<br>用刚刚那个图举例子，假设我们要插一个0进去：<br><img src="https://i.loli.net/2019/01/11/5c37dd492e812.png" style="zoom:50%"></p><h3 id="2-3-Trees"><a href="#2-3-Trees" class="headerlink" title="2-3 Trees"></a>2-3 Trees</h3><p>哦，这个就是branch factor=3的逼数，一个node最多可以有三个儿子，两个元素。</p><h2 id="Tries"><a href="#Tries" class="headerlink" title="Tries"></a>Tries</h2><p>这是一个用来保存各种字符串的树，因为重合部分很多，所以挺省内存的，插入之类的原理挺简单，只要会读里面有哪些字符串就可以了。<br>一般来讲，只要从root开始读，只要读到一个特殊的node就算字符串结尾（至于这个特殊的node怎么表示，不同的方法有轻微的区别，比如加一个空node，或者这个node有个特殊值，可以看一下上课老师怎么讲的）<br><img src="https://i.loli.net/2019/01/11/5c37ea6fe329b.png" style="zoom:50%"><br>好吧，假设上图里面绿色的node全都是终止node，那么上面这个trie里面存在的字符串有：a, an, and, any, all, be, been</p><h2 id="Huffman-Trees"><a href="#Huffman-Trees" class="headerlink" title="Huffman Trees"></a>Huffman Trees</h2><p>实现这个这个其实是CS 241的最后一个作业（压轴），但在151阶段，考试时给一个文本（或者每个字母对应的频率），能够手写一棵树就够。<br>huffman tree就是一个能够压缩文本的“密码表”，向左就记0，向右就记1，字母出现频率越高就离root越近，也就是说encode的二进制字符串就越短。<br>生成这棵树的方法，死记硬背的话很简单：找到频率最小的俩字母，连在同一个爸爸上，这个爸爸的值就是这两个的频率之和，然后把这个爸爸作为一个整体放到剩下的那堆字母里，再找两个频率最小的……直到表为空，最后一个爸爸就是root。<br><img src="https://i.loli.net/2019/01/11/5c3791ebaa2ef.png" alt="enter image description here"><br>根据上面的树，可以得到编码如下：<br> e  0 h  100  s  101  c  11<br>最后安利一篇<a href="http://mindhacks.cn/2011/07/10/the-importance-of-knowing-why-part3/" target="_blank" rel="external">关于huffman tree原理的高阶讲解</a>（在文章靠后的位置）</p><blockquote><p>参考链接<br><a href="https://www.cs.cornell.edu/courses/cs3110/2012sp/recitations/rec25-B-trees/rec25.html" target="_blank" rel="external">https://www.cs.cornell.edu/courses/cs3110/2012sp/recitations/rec25-B-trees/rec25.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一篇文章讲一下关于树的几个变种，lab里面并没有相关的内容，考试虽然也考但也不是重点。&lt;/p&gt;
&lt;h2 id=&quot;B-Trees-amp-2-3-Trees&quot;&gt;&lt;a href=&quot;#B-Trees-amp-2-3-Trees&quot; class=&quot;headerlink&quot; title=&quot;B-Trees &amp;amp; 2-3 Trees&quot;&gt;&lt;/a&gt;B-Trees &amp;amp; 2-3 Trees&lt;/h2&gt;&lt;p&gt;在最前面放一张凡凡制作的表情包：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/01/11/5c378b209ed47.jpg&quot; style=&quot;zoom:50%&quot;&gt;&lt;/p&gt;
&lt;p&gt;逼数，哦不，B-Tree是这样的，它的一个node里面可以存放好几个变量（可以用linked list来实现），也有不止一个儿子。这样它的层数比其他树都小，搜索起来也会更快。&lt;br&gt;因为一个node里面可以放不止一个变量，所以对于每个逼数，我们都规定一个branching factor t，代表最多能有几个儿子。&lt;/p&gt;
&lt;p&gt;B-Tree的特点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Every path from the root to a leaf has the same length（层高是统一的）&lt;/li&gt;
&lt;li&gt;If a node has  t  children, it contains  t−1  keys.（keys就是这个node里面的变量数）&lt;/li&gt;
&lt;li&gt;Every node (except the root) is at least half full.（每个node里面的变量数最少是n/2）&lt;/li&gt;
&lt;li&gt;The elements stored in a given subtree all have keys that are between the keys in the parent node on either side of the subtree pointer. (This generalizes the BST invariant.) &lt;/li&gt;
&lt;li&gt;The root has at least two children if it is not a leaf.&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Tree part 2 - 简单粗暴数据结构（6）</title>
    <link href="http://sheronw.github.io/2019/01/09/ds-tree2/"/>
    <id>http://sheronw.github.io/2019/01/09/ds-tree2/</id>
    <published>2019-01-10T04:33:35.000Z</published>
    <updated>2019-01-10T04:33:34.518Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Binary-Search-Trees"><a href="#Binary-Search-Trees" class="headerlink" title="Binary Search Trees"></a>Binary Search Trees</h2><p>BST是binary tree的一个变种（如名字所示，是便于搜索的变种……？），特点是这样的：<br>对于任何一个node来说，<br>左sub-tree的所有node都比它小，<br>右sub-tree的所有node都比他大。<br>（sub-tree就是以它的left child为root的tree）<br><img src="https://i.loli.net/2019/01/09/5c356a9fd8e70.png" alt="enter image description here"></p><a id="more"></a><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p>比较目标和root，目标更小就在左半边搜，目标更大就在右半边搜，这个用递归就很好实现。</p><h3 id="添加"><a href="#添加" class="headerlink" title="添加"></a>添加</h3><p>类似查找，如果比root小肯定要插在左半边的树里，如果比root大就要插在右半边，直到要搜的sub-tree为空为止。</p><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>删除就有点麻烦了，需要分类讨论：<br>首先我们要找到想要删除的那个node的位置吧，这个我们刚刚说了，这个node的位置有三种情况：</p><ol><li>它自己是个叶子，直接删了完事（如果是光杆root就return NULL吧）</li><li>它只有一个儿子（可能是左也可能是右），这种情况可以把以这个儿子为root的树整个挪到它所在的地方</li><li>它有两个儿子，这种情况就需要想一下了。根据binary search tree的定义，left sub-tree的值都要比right sub-tree里的小，而想要删除的这个node的值就在这两者之间，所以我们需要在这些node里面找出来一个也能满足这个条件的node然后替换掉。方法就是找到左边的树里面最大的（一路向右），或者右边的树里面最小的（一路向左）。</li></ol><h3 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h3><p>不难发现上面几个算法的时间复杂度（big-oh notation）和层数都有关系，但最操蛋的binary search tree 可能是长这样的：<br><img src="https://i.loli.net/2019/01/09/5c356ded29a72.png" alt="enter image description here"><br>如果你按照大小排序的顺序往里插入node，最后就会变成这个长歪了的狗样子，和List没什么区别了。也就是说最坏情况下层数就是n，因此是O(n)。<br>至于如何解决这个问题，请看下面：</p><h2 id="Balanced-Binary-Search-Trees"><a href="#Balanced-Binary-Search-Trees" class="headerlink" title="Balanced Binary Search Trees"></a>Balanced Binary Search Trees</h2><h3 id="AVL-Trees"><a href="#AVL-Trees" class="headerlink" title="AVL Trees"></a>AVL Trees</h3><p>维基百科的定义是这样的： In an AVL tree, the heights of the two child sub-trees of any node differ by at most one; if at any time they differ by more than one, rebalancing is done to restore this property.<br><img src="https://i.loli.net/2019/01/09/5c36121100904.png" alt="enter image description here"><br>这样，既然限制了两个sub-tree层高的差值，那么上面的问题似乎就解决了。不过问题来了，怎么让它rebalance啊……<br>答案就是，扭。</p><h4 id="Single-Rotation"><a href="#Single-Rotation" class="headerlink" title="Single Rotation"></a>Single Rotation</h4><p>怎么扭？要么往左，要么往右。<br>自己是爸爸的右儿子，爸爸也是爷爷的右儿子，就往左扭。<br>都是左儿子，就往右扭。<br><img src="https://i.loli.net/2019/01/09/5c3619efbc4c1.png" alt="enter image description here"></p><h4 id="Double-Rotation"><a href="#Double-Rotation" class="headerlink" title="Double Rotation"></a>Double Rotation</h4><p>可惜的是，这两种扭法好像并不能解决生活中出现的全部复杂情况，因此我们需要扭两次，先右再左或者先左再右。<br>先左再右适用于自己是爸爸的右儿子，爸爸是爷爷的左儿子这种拧巴的情况。先右再左适用于自己是爸爸的左儿子，爸爸是爷爷的右儿子这种情况。<br><img src="https://i.loli.net/2019/01/10/5c364008a425b.png" alt="enter image description here"></p><h4 id="轴的儿子该放哪儿"><a href="#轴的儿子该放哪儿" class="headerlink" title="轴的儿子该放哪儿"></a>轴的儿子该放哪儿</h4><p>这样，一共就四种怎么转的方法，但一个很微小的问题是，上面的几张图里面都没有画这几个node的全部sub-tree（好吧，我承认我比较懒）。<br>因为一个爸爸只能有两个儿子，一些儿子需要认新爸爸。认谁做爸爸呢？假设这个儿子没转之前是左儿子（比转轴小），那么就要认转完之后的新左儿子（比转轴小）做爸爸，做他的右儿子（比新爸爸大），反过来也同理。<br>直接用刚刚那张图了……红色是轴，蓝色是要认新爸爸的node。<br><img src="https://i.loli.net/2019/01/10/5c3644fe6b49e.png" alt="enter image description here"></p><h4 id="rebalance"><a href="#rebalance" class="headerlink" title="rebalance"></a>rebalance</h4><p>不论是插入新的node还是删除，基本上都是按照之前binary search tree的套路，只不过要更新一下每棵树的层高，还有balance factor（就是左sub-tree的层高减去右边的），一旦发现有不平衡的情况，就判断是上面的哪种情况，然后转。</p><p><a href="https://www.cs.usfca.edu/~galles/visualization/AVLtree.html" target="_blank" rel="external">我在网上找到了一个演示AVL Tree的页面</a></p><h4 id="时间复杂度-1"><a href="#时间复杂度-1" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><p>因为AVL不会斜的太厉害，所以树的层高和n都是对数关系，这几个算法的时间复杂度都是O(logn)。</p><h3 id="Red-Black-Trees"><a href="#Red-Black-Trees" class="headerlink" title="Red-Black Trees"></a>Red-Black Trees</h3><p>红黑树也是一种改进的binary search tree，只不过node有红有黑，所有的叶子都是一种叫做NIL的黑node，里面不存放任何数据。<br>这是<a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree" target="_blank" rel="external">wikipedia</a>中关于红黑树的定义：</p><ol><li>Each node is either red or black.</li><li>The root is black. </li><li>All leaves (NIL) are black.</li><li>If a node is red, then both its children are black.</li><li>Every path from a given node to any of its descendant NIL nodes contains the same number of black nodes.</li></ol><p>和AVL一样，想要保持它的这些特性，就需要在添加或者删除之后进行rebalance。扭在这里仍然好用，但我们还需要重新涂色。</p><h4 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h4><p>因为每一个路径都要有同样的black node，所以新node作为red node插进去是最简单的方法。<br>用binary search tree的方法插入，被插的node（我们就叫N吧）最后都是叶子，可是规则3告诉我们所有的叶子都是NIL，因此我们需要把某个NIL替换成N（附赠两个NIL儿子）。<br>下面是所有可能出现的情况：</p><ol><li>N自己是root</li><li>N的爸爸就是黑的</li><li>N的爸爸是红的，舅舅也是红的</li><li>N的爸爸是红的，舅舅是黑的</li></ol><p>第一种就很好解决啦，把N涂成黑色的就OK。<br>第二种的话也好解决，其实就是把一个黑node替换成了一个（有两个黑儿子的）红node，每条路径上黑node的数量不变，不用做其他处理。<br>第三种靠重新涂色来解决，爸爸和舅舅都涂黑，然后爷爷涂红，这样个树上所有的路径黑node的数量仍然不变。但这样就有了一个问题——万一爷爷就是root怎么办呢？方法是处理完之后再对爷爷使用一次这个function。<br>第四种就麻烦了，因为这种情况下我们要扭。和AVL相似，我们需要四种不同的情况：<br>（下面的图示中，假设从g出发的每条路径上的黑node数为n，T代表subtree而不是NIL，T下面写的是这个tree种每条路径上的黑node数量）</p><h5 id="Left-Rotation"><a href="#Left-Rotation" class="headerlink" title="Left Rotation"></a>Left Rotation</h5><p>此情况适用于自己是爸爸的右儿子，爸爸是爷爷的右儿子的时候。<br>扭完之后右侧分支的黑node数不变，左侧多了一个黑node（g），因此我们把g涂红，让数目恢复原状。T<sub>3</sub>之前和红色的p混，因此不用考虑它的颜色是否和红色node兼容。<br><img src="https://i.loli.net/2019/01/10/5c36ad5f9a825.png" alt="enter image description here"></p><h5 id="Right-Rotation"><a href="#Right-Rotation" class="headerlink" title="Right Rotation"></a>Right Rotation</h5><p>此情况适用于自己是爸爸的左儿子，爸爸是爷爷的左儿子的时候。<br>扭完之后你会发现左侧sub-tree的黑node数目没变，而右边多了一个黑node（g），所以我们把g涂成红色。因为T<sub>3</sub>之前就和红色的p混，所以不用考虑重新处理。<br><img src="https://i.loli.net/2019/01/10/5c36a23f5b5ad.png" alt="enter image description here"></p><h5 id="Left-Right-Rotation"><a href="#Left-Right-Rotation" class="headerlink" title="Left-Right Rotation"></a>Left-Right Rotation</h5><p>适用于自己是爸爸的右儿子，爸爸却是爷爷的左儿子的情况。<br><img src="https://i.loli.net/2019/01/10/5c36b992cefb4.png" alt="enter image description here"></p><h5 id="Right-Left-Rotation"><a href="#Right-Left-Rotation" class="headerlink" title="Right-Left Rotation"></a>Right-Left Rotation</h5><p>适用于自己是爸爸的左儿子，爸爸却是爷爷的右儿子的情况。<br><img src="https://i.loli.net/2019/01/10/5c36b73474c33.png" alt="enter image description here"></p><h4 id="时间复杂度-2"><a href="#时间复杂度-2" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><p>和之前AVL同理，也是O(logn)。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Binary-Search-Trees&quot;&gt;&lt;a href=&quot;#Binary-Search-Trees&quot; class=&quot;headerlink&quot; title=&quot;Binary Search Trees&quot;&gt;&lt;/a&gt;Binary Search Trees&lt;/h2&gt;&lt;p&gt;BST是binary tree的一个变种（如名字所示，是便于搜索的变种……？），特点是这样的：&lt;br&gt;对于任何一个node来说，&lt;br&gt;左sub-tree的所有node都比它小，&lt;br&gt;右sub-tree的所有node都比他大。&lt;br&gt;（sub-tree就是以它的left child为root的tree）&lt;br&gt;&lt;img src=&quot;https://i.loli.net/2019/01/09/5c356a9fd8e70.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Tree part 1 - 简单粗暴数据结构（5）</title>
    <link href="http://sheronw.github.io/2019/01/07/ds-tree1/"/>
    <id>http://sheronw.github.io/2019/01/07/ds-tree1/</id>
    <published>2019-01-08T03:54:35.000Z</published>
    <updated>2019-01-08T03:59:31.932Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Basic-Terminology"><a href="#Basic-Terminology" class="headerlink" title="Basic Terminology"></a>Basic Terminology</h2><p><img src="https://i.loli.net/2019/01/08/5c34127fa2bf6.png" alt="enter image description here"><br>树，它有一个树干，然后分成很多树枝，树枝再有很多分支（好吧我可能在说废话）。虽然这么说，“树”作为一个数据结构，它通常是倒过来画的，不如说是根更合适hhh<br>和表栈队列不同的是，树是我们接触的第一个非线性（nonlinear）的数据结构（所以难度会飙升）。<br>就和之前的linked list一样，树中的每个单元都是一个node。<br>既然不是线性的，树中的那些nodes是如何联系起来的呢？<br>近一点说，两个node之间是由edge相连（好像是废话），就是图示里面的那条线。<br>那宏观一点呢，一般来讲，树干死了基本上树枝也得挂，所以树干比树枝牛逼——你可以看到，树这个结构是有“阶级制度”的。</p><a id="more"></a><p>每棵树最顶上的那个node叫root（根）。<br>只要一个node在另一个node上面，那么它就是爸爸parent，另外一个就是child儿子。（是的，在lab里面还会看到爷爷和叔伯）<br>如果一个node没有儿子，那么它就是最low的，叫leaf。<br>height是<strong>一棵树</strong>从root到某个leaf的最长路径长度。<br>depth是<strong>一个node</strong>到root的路径长度。</p><h2 id="Binary-Tree"><a href="#Binary-Tree" class="headerlink" title="Binary Tree"></a>Binary Tree</h2><p>这就简单了，binary嘛，每一个node都顶多俩儿子，一个叫left child另一个叫right child（如果有的话）。<br><img src="https://i.loli.net/2019/01/08/5c341a504448a.png" alt="enter image description here"></p><h2 id="Tree-traversals"><a href="#Tree-traversals" class="headerlink" title="Tree traversals"></a>Tree traversals</h2><p>因为树不是线性的，所以访问不同node的先后顺序也有很多：</p><h3 id="depth-first"><a href="#depth-first" class="headerlink" title="depth first"></a>depth first</h3><p>其实就是把每个node都当作是某个sub-tree的root然后写递归……下面这三种也只是顺序不太一样而已。而且不觉得这些前缀有些眼熟嘛，就是之前讲的不同运算顺序啊！（可以对比一下想想看hhh？）</p><h4 id="in-order"><a href="#in-order" class="headerlink" title="in-order"></a>in-order</h4><p>爸爸在中间，儿子站两边。<br>用上面的那个图举例子：D B E A F C</p><pre><code>inorder(root):    if root is not NULL:        inorder(root&apos;s left child)        visit root        inorder(root&apos;s right child)</code></pre><h4 id="pre-order"><a href="#pre-order" class="headerlink" title="pre-order"></a>pre-order</h4><p>爸爸站最前面，两个儿子站后面。<br>上图例子：A B D E C F</p><pre><code>preorder(root):    if root is not NULL:        visit root        inorder(root&apos;s left child)        inorder(root&apos;s right child)</code></pre><h4 id="post-order"><a href="#post-order" class="headerlink" title="post-order"></a>post-order</h4><p>爸爸殿后，两个儿子打头阵。<br>上图例子：D E B F C A</p><pre><code>inorder(root):    if root is not NULL:        inorder(root&apos;s left child)        inorder(root&apos;s right child)        visit root</code></pre><h3 id="breath-first"><a href="#breath-first" class="headerlink" title="breath first"></a>breath first</h3><p>也就是说level first。一层一层来，从左到右。<br>上图例子：A B C D E F<br>这个的算法就要用到刚刚讲的队列了：</p><pre><code>create an empty queueenqueue rootwhile queue is not empty:    dequeue a node N    visit N    if N&apos;s left child is not NULL:        enqueue N&apos;s left child    if N&apos;s right child is not NULL:        enqueue N&apos;s right child</code></pre><h2 id="Implementing-Binary-Trees"><a href="#Implementing-Binary-Trees" class="headerlink" title="Implementing Binary Trees"></a>Implementing Binary Trees</h2><p>这段等学完java再仔细讲。<br>和linked list一样，都需要一个叫做node的单元，只不过把prev和next换成了left和right而已。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Basic-Terminology&quot;&gt;&lt;a href=&quot;#Basic-Terminology&quot; class=&quot;headerlink&quot; title=&quot;Basic Terminology&quot;&gt;&lt;/a&gt;Basic Terminology&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/01/08/5c34127fa2bf6.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;br&gt;树，它有一个树干，然后分成很多树枝，树枝再有很多分支（好吧我可能在说废话）。虽然这么说，“树”作为一个数据结构，它通常是倒过来画的，不如说是根更合适hhh&lt;br&gt;和表栈队列不同的是，树是我们接触的第一个非线性（nonlinear）的数据结构（所以难度会飙升）。&lt;br&gt;就和之前的linked list一样，树中的每个单元都是一个node。&lt;br&gt;既然不是线性的，树中的那些nodes是如何联系起来的呢？&lt;br&gt;近一点说，两个node之间是由edge相连（好像是废话），就是图示里面的那条线。&lt;br&gt;那宏观一点呢，一般来讲，树干死了基本上树枝也得挂，所以树干比树枝牛逼——你可以看到，树这个结构是有“阶级制度”的。&lt;/p&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Arithmetic expression - 简单粗暴数据结构（4）</title>
    <link href="http://sheronw.github.io/2019/01/06/ds-arithmetic_expression/"/>
    <id>http://sheronw.github.io/2019/01/06/ds-arithmetic_expression/</id>
    <published>2019-01-06T23:58:47.000Z</published>
    <updated>2019-01-07T02:08:26.646Z</updated>
    
    <content type="html"><![CDATA[<h2 id="infix-prefix-postfix"><a href="#infix-prefix-postfix" class="headerlink" title="infix, prefix, postfix"></a>infix, prefix, postfix</h2><p>如下是三种不同的表达式的写法：</p><h3 id="infix"><a href="#infix" class="headerlink" title="infix"></a>infix</h3><p>就是我们从小学到现在一直用的那种。<br>举个例子吧：(A+B)/C-D*C<br>一般来说运算符号都是放在两个数中间的，默认从左到右、不同符号优先级不同，还有括号来规定运算顺序。<br>当然，虽然你懂怎么算，但除非特殊说明，计算机并不知道哪个优先，所以有一种叫做fully parenthesized expression的东西，大概是这样的：(((A+B)/C)-(D*C))。</p><a id="more"></a><h3 id="prefix"><a href="#prefix" class="headerlink" title="prefix"></a>prefix</h3><p>prefix，顾名思义，就是运算符号放在了两个数字前面，比如这样：A + B变成了+ A B<br>那之前的(A+B)/C-D*C要怎么写呢？从最小的单位（比如A+B）开始改成prefix，然后把这个单位作为一个整体带入到下一轮的转换中：- / + A B C * D C</p><h3 id="postfix"><a href="#postfix" class="headerlink" title="postfix"></a>postfix</h3><p>postfix就同理了，只不过符号在数字后面，比如之前的(A+B)/C-D*C就是 A B + C / D C * -</p><h2 id="expression-objects"><a href="#expression-objects" class="headerlink" title="expression objects"></a>expression objects</h2><p>在还没有讲面向对象之前，这一块儿都跳过。反正下面的算法里面在实际程序里面带去的的都不是字符，而是两种不同的东西——要么是一种叫做『运算符』的object，要么是一种叫『数字』的object。</p><h2 id="infix-to-postfix-algorithm"><a href="#infix-to-postfix-algorithm" class="headerlink" title="infix-to-postfix algorithm"></a>infix-to-postfix algorithm</h2><p>这个算法中用栈来暂存运算符号。建议你自己在纸上找一个infix然后自己写写看看hhh<br>首先我们有了一串用infix表示的式子，我们从左到右每次读取一个运算符号或者数字x：<br>如果x是左括号，那么就把它放到stack上；<br>如果x是数字，就把它放到postfix的列表里；<br>如果x是符号，比较x和stack最上面那个符号的优先级，把优先级大于等于它的符号全拿出来放到postfix里，再把x放到stack上；<br>如果x是右括号，就把x丢掉，再把stack上所有东西一个一个拿出来放到postfix里，直到遇到左括号，拿出来删掉。<br>然后最后postfix里面就是我们想要的了。</p><h2 id="evaluate-postfix-algorithm"><a href="#evaluate-postfix-algorithm" class="headerlink" title="evaluate postfix algorithm"></a>evaluate postfix algorithm</h2><p>这个就和我们之前手动转换infix和postfix的原理很像了，就是两个数字和一个运算符号作为一个小单元。<br>还是那样子，还是需要一个stack，假设我们有一串用postfix表示的式子，从左到右每次读取一个运算符号或者数字x：<br>如果x是一个数字，就放在stack上；<br>如果x是一个运算符号，就把stack最上面的两个数拿出来（最先拿出来的是正常从左到右运算里面的第二个数），算一个数值，再把这个数放回stack上；<br>最后，如果式子正确，读取完毕后，stack上应该只有唯一的一个数，这个就是我们所要求的结果。</p><p><a href="http://interactivepython.org/runestone/static/pythonds/BasicDS/InfixPrefixandPostfixExpressions.html" target="_blank" rel="external">可以参考这里</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;infix-prefix-postfix&quot;&gt;&lt;a href=&quot;#infix-prefix-postfix&quot; class=&quot;headerlink&quot; title=&quot;infix, prefix, postfix&quot;&gt;&lt;/a&gt;infix, prefix, postfix&lt;/h2&gt;&lt;p&gt;如下是三种不同的表达式的写法：&lt;/p&gt;
&lt;h3 id=&quot;infix&quot;&gt;&lt;a href=&quot;#infix&quot; class=&quot;headerlink&quot; title=&quot;infix&quot;&gt;&lt;/a&gt;infix&lt;/h3&gt;&lt;p&gt;就是我们从小学到现在一直用的那种。&lt;br&gt;举个例子吧：(A+B)/C-D*C&lt;br&gt;一般来说运算符号都是放在两个数中间的，默认从左到右、不同符号优先级不同，还有括号来规定运算顺序。&lt;br&gt;当然，虽然你懂怎么算，但除非特殊说明，计算机并不知道哪个优先，所以有一种叫做fully parenthesized expression的东西，大概是这样的：(((A+B)/C)-(D*C))。&lt;/p&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Algorithm Analysis - 简单粗暴数据结构（3）</title>
    <link href="http://sheronw.github.io/2019/01/05/ds-algs_analysis/"/>
    <id>http://sheronw.github.io/2019/01/05/ds-algs_analysis/</id>
    <published>2019-01-06T04:32:05.000Z</published>
    <updated>2019-01-06T04:41:00.482Z</updated>
    
    <content type="html"><![CDATA[<h2 id="big-oh-notation"><a href="#big-oh-notation" class="headerlink" title="big-oh notation"></a>big-oh notation</h2><p>其实大O符号的标准定义是这样的：<br>设f和g是定义域为自然数集N上的函数，若存在正数c和n，使得对一切n&gt;n<sub>0</sub>，0&lt;=f(n)&lt;=cg(n)成立，则称<strong>f(n)的渐进上界g(n)，记作f(n)=O(g(n))</strong>。<br>……虽然我希望你认真地 阅读以上定义并理解，但如果是非本专业的学生，只是学学数据结构的话，算法分析方面的知识只要下狠心背下来就ok，这个定义不看也可以的（当然知道这玩意儿是渐进上界倒是能够帮助理解）。</p><a id="more"></a><p>大白话来讲（虽然可能这么说有点差错），big-oh notation就是一个近似函数，而且是比原函数要大的那种。当然也不要求一直都大，但一定要在某个值之后一定比这个值要大。<br>大概就是下图这样？不要纠结函数形状，只要g(n)超过一个值之后一直比O(g(n))大就行……<br><img src="https://i.loli.net/2019/01/06/5c31685b1e670.png" alt="enter image description here"><br>几个在这个阶段会比较有用的定理：</p><ul><li>if f(n) is O(c*g(n)) for some constant c, then f(n) is O(g(n))</li><li>(前面的系数是可以忽略的)</li><li>If f<sub>1</sub>(n) is O(g<sub>1</sub>(n))and f<sub>2</sub>(n) is O(g<sub>2</sub>(n), then f<sub>1</sub>(n)+f<sub>2</sub>(n) is O(max(g<sub>1</sub>(n), g<sub>2</sub>(n))</li><li>(两个函数相加，对长远趋势起决定性作用的肯定是增的更快的那个，所以忽略更小的函数)</li><li>对数的底并不重要（有个公式也很好推导，不放了）</li></ul><h2 id="running-times-for-common-algorithms"><a href="#running-times-for-common-algorithms" class="headerlink" title="running times for common algorithms"></a>running times for common algorithms</h2><p>但是，这个big-oh notation到底有什么用呢？它是衡量一个程序（或者说，算法）好坏的重要指标。毕竟我们总是希望一个程序需要的内存越少越好，运行的时间越快越好。因为这节课没有涉及内存（空间复杂度）的分析，所以只需要知道如何分析时间就好了。<br>程序运行的时间其实和运行这个程序的机器还有编译器之类的都有关，但我们暂时不去管它们，那么还有关的就是输入的<strong>数据量</strong>（也就是说n）还有<strong>算法</strong>本身了。running time就是一个自变量为n的函数，但因为还有别的影响因素，也没有那个成本一个个程序统计精确的函数值（也不需要），所以就用到了近似函数Big-Oh notation啦。<br>当然，同一个算法，由于输入的数据不同，running time也是不一样的，总的来说，有如下三种：</p><ul><li>best-case running time</li><li>average-case running time</li><li>worst-case running time</li></ul><p>默认情况下，都是分析worst-case running time，毕竟最坏情况下的运行时间也肯定是平均情况的上界……best-case感觉很少分析，因为好像没用……？</p><p>举个例子，最简单粗暴的线性搜索，共有n个数据，for循环从第一个开始一个个查的那种。</p><ul><li>要是我们人品好，发现第一个就是我们要的，一次就搜到了，best-case running time就是O(1)。</li><li>要是我们运气没那么差，数据的index在1~n-1之间，那也是小于n的某个值，不会超过n，那么渐进上界仍然是n，average-case running time就是O(n)。</li><li>要是正好最后一个数据才是我们要找的……就说明我们搜了n次，worst-case running time还是O(n)。</li></ul><p>那么其他的程序怎么分析呢？<br>遇到循环体，不管是for还是while先看看这段程序要运行几次（用n表示），然后它就是循环的这部分前面的系数。<br>而一段程序可以分为多个运行部分的和，按照前面的定理，只要找出最耗时间的那一部分，剩下的全忽略就好。</p><pre><code>printf(&quot;WOW&quot;); //不管输入的数据有多少，运行上面这行代码所需要的都是常数时间，只要是常数时间都算O(1)for(int i=0;i&lt;n;i++){//运行了n次    printf(&quot;???&quot;);    //同理O(1)}//所以是O(1+n*1)=O(n)</code></pre><p>Binary Search是O(logn)，这个显然比刚刚那个快。大概就是给定一堆排好序的数据，看看中间的数据比搜索数据大还是小，这样就可以排除一半的数据，然后以此类推，最坏的情况是直到搜索范围只剩下1。<br>因为每次比较搜索数据和数据中的某个数据哪个大都是常数时间，所以只需要找出最坏要搜索多少次就可以了。如果一共有8个数据，第一次没搜到，缩小到4个数据，还没找到，缩小到2个数据……你会发现数据的总数=2^(总搜索次数)，也就是说总搜索次数=log<sub>2</sub>n，也就是O(logn)。</p><h2 id="recurrence-relations"><a href="#recurrence-relations" class="headerlink" title="recurrence relations"></a>recurrence relations</h2><p>虽然老师上课没这么讲，但我觉得对付递归的最好方法是一个叫做递归树的画图方法。<br>比如用递归来求斐波那契数列吧（请注意，这是一个非常糟糕的算法）。<br>伪代码差不多是这样事儿的：</p><pre><code>f(n):    if n==0 or n==1:        return n    else:        return f(n-1)+f(n-2)</code></pre><p>首先，要找出来T(n)和下一层递归的关系。在n比较大的情况下，想求f(n)就要把f(n-1)和f(n-2)都算出来，两个都需要时间，而得到这两个值之后相加是常数时间O(1)，所以关系就是T(n)=T(n-1)+T(n-2)。<br>递归树的原理是这样的，先在每一个节点都写上这一层需要运行的时间，然后把这个运行时间拆成一棵树，只属于这个节点的运行时间留下，剩下的放到下一层。每画一个树，三个节点的和都等于没拆分之前单独一个节点的运行时间。<br><img src="https://i.loli.net/2019/01/06/5c317ff7b4aa8.png" alt="enter image description here"><br>这样我们就画出来了一棵树……其实每个分支节点的高度不应该是一样的，但毕竟是渐进上界嘛，这个树差不多有n层（最长的那一条应该是一路往左，每次减一），每个节点是O(1)，那么T(n)=O(1)+O(2)+O(4)+…+O(2<sup>n</sup>)，按照公式T(n)=O(2<sup>n</sup>)。<br>所以这个玩意儿显然是成指数增长的，数一大就会变得巨慢无比（不信可以跑跑看看），不是个好算法……<br>一般来说，O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n^a)&lt;O(a^n)，a是一个常数</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;big-oh-notation&quot;&gt;&lt;a href=&quot;#big-oh-notation&quot; class=&quot;headerlink&quot; title=&quot;big-oh notation&quot;&gt;&lt;/a&gt;big-oh notation&lt;/h2&gt;&lt;p&gt;其实大O符号的标准定义是这样的：&lt;br&gt;设f和g是定义域为自然数集N上的函数，若存在正数c和n，使得对一切n&amp;gt;n&lt;sub&gt;0&lt;/sub&gt;，0&amp;lt;=f(n)&amp;lt;=cg(n)成立，则称&lt;strong&gt;f(n)的渐进上界g(n)，记作f(n)=O(g(n))&lt;/strong&gt;。&lt;br&gt;……虽然我希望你认真地 阅读以上定义并理解，但如果是非本专业的学生，只是学学数据结构的话，算法分析方面的知识只要下狠心背下来就ok，这个定义不看也可以的（当然知道这玩意儿是渐进上界倒是能够帮助理解）。&lt;/p&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Stack &amp; Queue - 简单粗暴数据结构（2）</title>
    <link href="http://sheronw.github.io/2019/01/04/ds-stackandqueue/"/>
    <id>http://sheronw.github.io/2019/01/04/ds-stackandqueue/</id>
    <published>2019-01-05T01:57:50.000Z</published>
    <updated>2019-01-05T01:57:30.326Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Stack，中文名叫栈。<br>和之前说到的表一样都是线性的数据结构。但区别是只能在一个方向上进行添加或者移除的操作，也就是先进先出。比较形象化的比喻是，一沓盘子，每次只能取走最上面的那个盘子，或者在最上面放一个盘子。<br>至于可以执行的操作，可以看<a href="https://docs.oracle.com/javase/7/docs/api/java/util/Stack.html" target="_blank" rel="external">官方文档</a>。加盘子叫push，拿盘子叫pop，查看最上面的盘子是啥（但是不拿走）叫peek。<br><a id="more"></a></p><p>Queue，中文名叫队列。<br>和stack很像，只不过这次是先进后出，就像排队等车一样，前面的人上车走了，新来的人要排队尾。<br><a href="https://docs.oracle.com/javase/7/docs/api/java/util/Queue.html" target="_blank" rel="external">官方文档</a>，拉新人排队叫enqueue，前面的人上车叫dequeue，peek是看排在最前面的是谁（但不叫上车）。</p><p>Deque，全称是double-ended queue，它作为一个队列就比较牛逼了，不管是队尾还是对首都可以随便加人或者拉人，就像一个只能在表尾或者表首进行添加删除操作的List……</p><h2 id="Implementations"><a href="#Implementations" class="headerlink" title="Implementations"></a>Implementations</h2><p>老样子，2 implementations: Array &amp; LinkedList</p><h3 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h3><p>用array来implement的话就很简单了，而且方法显然不止一种。首先我们需要一个计数器n来记录这个stack里面有多少个盘子，空的时候默认为0，这样最上面的盘子index就是n-1，peek就可以直接读n-1这个格子的值了，加盘子就加到第n个格子里面然后更新计数器为n+1，拿盘子同理。如果遇到array不够用的情况，就用之前在list里面遇到的方法把容量扩充一下。<br>用linked list的话更简单，只要把之前list里面添加或者删除node的操作在最前面那里操作一下然后改一下计数器就可以了。</p><h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><p>用array的话，首先可以用front和back两个变量来记录队首和队尾的坐标，然后和刚刚一样添加删除，就是下图的这种情况：<br><img src="https://i.loli.net/2019/01/05/5c3006700c652.png" alt="草图.png"><br>然后你会惊恐地发现现在已经没法再往里加任何新的东西了……但这个array却有大块的内存没被填满，和之前一样将array扩充显然不是一个好主意hmmmm<br>为了让前面那块内存不白白浪费，把之后新加进来的东西放进去可能是个好主意。具体怎么放呢？想象这个array就是一张纸，然后把这张纸卷起来首尾相连，然后按照之前的方法添加删除就好啦！这样只有里面空间全满才需要重新将array扩充了。</p><p>可是如果这么做的话，在front或者back的index变成n（就是这个array的容量）的时候，显然这个index不合法，毕竟不能再往后加了，这个时候要把这个index改成零重新来过了。（实际操作的时候在每个地方写判断语句显然很麻烦，不如写一个function然后每次用到index的时候都调用）<br>array扩充的时候也要小心，不能和之前的list一样从头复制到尾，应该把最前面的东西放在index为零的位置，然后一个一个向后。<br><img src="https://i.loli.net/2019/01/05/5c300de927fbe.png" alt="enter image description here"><br>用linked list的话就没什么难度了，还是添加删除node然后更新计数器的操作。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Definition&quot;&gt;&lt;a href=&quot;#Definition&quot; class=&quot;headerlink&quot; title=&quot;Definition&quot;&gt;&lt;/a&gt;Definition&lt;/h2&gt;&lt;p&gt;Stack，中文名叫栈。&lt;br&gt;和之前说到的表一样都是线性的数据结构。但区别是只能在一个方向上进行添加或者移除的操作，也就是先进先出。比较形象化的比喻是，一沓盘子，每次只能取走最上面的那个盘子，或者在最上面放一个盘子。&lt;br&gt;至于可以执行的操作，可以看&lt;a href=&quot;https://docs.oracle.com/javase/7/docs/api/java/util/Stack.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官方文档&lt;/a&gt;。加盘子叫push，拿盘子叫pop，查看最上面的盘子是啥（但是不拿走）叫peek。&lt;br&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>the List interface - 简单粗暴数据结构（1）</title>
    <link href="http://sheronw.github.io/2019/01/03/ds-list/"/>
    <id>http://sheronw.github.io/2019/01/03/ds-list/</id>
    <published>2019-01-04T01:45:50.000Z</published>
    <updated>2019-03-03T03:04:45.988Z</updated>
    
    <content type="html"><![CDATA[<h1 id="The-List-Interface"><a href="#The-List-Interface" class="headerlink" title="The List Interface"></a>The List Interface</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>顾名思义，就是一个表。<br>按照惯例，index从零开始，每一个元素都有一个相应的index。<br>至于可以执行的操作，可以看<a href="https://docs.oracle.com/javase/7/docs/api/java/util/List.html" target="_blank" rel="external">官方文档</a>。比较基本的有添加、删除、查找等。<br><a id="more"></a></p><h2 id="Implementations"><a href="#Implementations" class="headerlink" title="Implementations"></a>Implementations</h2><p>2 implementations: ArrayList &amp; LinkedList</p><h3 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h3><p>什么是Array？<br>我的理解是，指定数据型（或者object）T，array可以在内存里面画出一块区域来储存<strong>给定数量</strong>的T。因此array的长度在初始化时必须声明。之后也不能改。<br>所以用array来搞list的话，其实还是挺麻烦的，比如在非list的结尾进行删除或者添加的操作，就得把所有后面的元素一个一个往后挪。<br>还有一个就是，因为array是给定数量的，但list指不定会往里加多少东西，所以一旦这个array快满了的时候我们就得新建一个array，把现有元素都一个个复制到新的里面，然后重定向list的array指针为这个新的array。<br>（*其实并不是真的用到了指针这个东西，只是为了帮助理解，具体的之后会说）<br><img src="https://i.loli.net/2019/01/04/5c2eaff197a53.png" alt="enter image description here"></p><h3 id="Linked-List"><a href="#Linked-List" class="headerlink" title="Linked List"></a>Linked List</h3><p>linked list就是一串首尾相连的单位，每个单位叫node。<br>最基本的node里面需要两种东西，第一种是这个node里面真正储存的数据，另外一种是指向下一个node的指针next。</p><h4 id="head-and-tail-pointers"><a href="#head-and-tail-pointers" class="headerlink" title="head and tail pointers"></a>head and tail pointers</h4><p>为了让我们能够在处理的时候能够找得着北，我们需要知道哪一个node是第一个，哪一个node是最后一个。每一个这样的liked list里面都有一个head node和一个tail node，指向相应的node，进行添加删除首尾node之类的操作的时候需要相应地update。<br>至于如何添加或删除node，首先我们需要一个叫做iterator的特殊的node指针来确定我们正在操作的node是哪一个（就跟基础课里面while循环的index计数器i一样），将它挪到相应的位置之后新建一个node并赋值，然后就是相关的几个指向的替换游戏了hmmm<br><img src="https://i.loli.net/2019/01/04/5c2eba55b74be.png" alt="enter image description here"></p><h4 id="doubly-linked"><a href="#doubly-linked" class="headerlink" title="doubly-linked"></a>doubly-linked</h4><p>其实和前面那种差不多，区别就是前面的是单向箭头，现在变双向了，每一个node里面都有一个指向后一个node的prev和指向下一个node的next。</p><h4 id="circular"><a href="#circular" class="headerlink" title="circular"></a>circular</h4><p>虽然还是需要head提醒我们哪里是开头，但这次我们不要tail了，直接把最后一个连到第一个node上。</p><h4 id="sentinel-nodes"><a href="#sentinel-nodes" class="headerlink" title="sentinel nodes"></a>sentinel nodes</h4><p>circular的升级版，可以把这个sentinel node想象成项链上的那个搭扣，连接了第一个node和最后一个node。</p><p><img src="https://i.loli.net/2019/01/04/5c2eb80d92f81.png" alt="enter image description here"></p><p><a href="https://www.tutorialspoint.com/data_structures_algorithms/linked_list_algorithms.htm" target="_blank" rel="external">https://www.tutorialspoint.com/data_structures_algorithms/linked_list_algorithms.htm</a><br><a href="https://www.tutorialspoint.com/data_structures_algorithms/doubly_linked_list_algorithm.htm" target="_blank" rel="external">https://www.tutorialspoint.com/data_structures_algorithms/doubly_linked_list_algorithm.htm</a><br><a href="https://www.tutorialspoint.com/data_structures_algorithms/circular_linked_list_algorithm.htm" target="_blank" rel="external">https://www.tutorialspoint.com/data_structures_algorithms/circular_linked_list_algorithm.htm</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;The-List-Interface&quot;&gt;&lt;a href=&quot;#The-List-Interface&quot; class=&quot;headerlink&quot; title=&quot;The List Interface&quot;&gt;&lt;/a&gt;The List Interface&lt;/h1&gt;&lt;h2 id=&quot;Definition&quot;&gt;&lt;a href=&quot;#Definition&quot; class=&quot;headerlink&quot; title=&quot;Definition&quot;&gt;&lt;/a&gt;Definition&lt;/h2&gt;&lt;p&gt;顾名思义，就是一个表。&lt;br&gt;按照惯例，index从零开始，每一个元素都有一个相应的index。&lt;br&gt;至于可以执行的操作，可以看&lt;a href=&quot;https://docs.oracle.com/javase/7/docs/api/java/util/List.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官方文档&lt;/a&gt;。比较基本的有添加、删除、查找等。&lt;br&gt;
    
    </summary>
    
      <category term="简单粗暴数据结构" scheme="http://sheronw.github.io/categories/%E7%AE%80%E5%8D%95%E7%B2%97%E6%9A%B4%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>2018年度书单</title>
    <link href="http://sheronw.github.io/2018/12/31/2018booklist/"/>
    <id>http://sheronw.github.io/2018/12/31/2018booklist/</id>
    <published>2019-01-01T01:35:17.000Z</published>
    <updated>2019-02-24T21:17:18.480Z</updated>
    
    <content type="html"><![CDATA[<p>我觉得我今年没怎么读书，准确来讲是没逼着自己读书，结果就是读了好多虚构类(其实就是小说……)<br><a id="more"></a></p><ol><li>《人月神话》 Frederick P. Brooks, Jr.</li><li>《China’s Urban Billion》 Tom Miller</li><li>《生命是什么》 薛定谔</li><li>《黑暗时代的她们》 杰奎琳 罗斯</li><li>《欢乐英雄》 古龙</li><li>《觅渡》 梁衡</li><li>《白》 原研哉</li><li>《激荡三十年 ：中国企业1978-2008》 吴晓波</li><li>《激荡十年，水大鱼大 2008-2018》 吴晓波</li><li>《呐喊》 鲁迅</li><li>《直到最后一句》 卢丽莉</li><li>《布鲁克林有棵树》贝蒂 史密斯</li><li>《人类简史》 尤瓦尔 赫拉利</li><li>《未来简史》 尤瓦尔 赫拉利</li><li>《爱上她的12种方法》 入间人间</li><li>《后羿》 叶兆言</li><li>《红玫瑰与白玫瑰》 张爱玲</li><li>《文心》夏沔尊 叶圣陶</li><li>《下流社会》三浦展</li></ol><p>八本虚构类文学里面，《后羿》和《直到最后一句》都是二刷，而且还是明明知道评价不怎么样但是因为各种各样的共鸣感还是去二刷了的那种，不评价。<br>梁衡的散文集真的是因为被写瞿秋白和项羽的那篇给惊艳到了(毕竟是喜欢了一整个中学时代的文章)才买的，之后发现文笔不错官腔太多，不太喜欢。<br>忘了在哪儿听说了红白玫瑰就去图书馆借了本张爱玲，对这种小布尔乔亚不太感兴趣，但这个两性关系的研究是真滴巧妙，虽然我我不知道为什么一看到男主内心戏就觉得膝盖中枪，读完赶紧借了本同时代的鲁迅。<br>入间人间那本还是电波系，一个男的被另外一个男的和自己喜欢的妹子虐狗，没有之前660有意思。<br>布鲁克林里面人名太难记，不过毕竟是几十年前的美国鸡汤，平平淡淡读着挺舒服的。<br>《欢乐英雄》受众比较广也不烧脑，而且我就是喜欢古龙比金庸更多一些。</p><p>非虚构类，《人月神话》差不多算是软工专业书了，薛定谔的那本也烧脑，但努力get到他在说啥时候就会觉得卧槽这个人怎么这么聪明，看世界的角度都变得物理学家了起来。<br>《文心》更适合给初中生普及语文知识，学校的语文课真的很不到位。<br>黑暗时代的她们就是致敬类传记，在西方很政治正确的那种，几个妹子我都喜欢，翻译略差。<br>原研哉那本还是《设计中的设计》的核心思想，只不过挑出来一部分细讲了。<br>《中国十亿城民》(虽然我看的是英文版)和《下流社会》都不是太新鲜的书，但里面的问题都显然没解决，一个是发展中国家城市化的冲突，另一个是发达国家看不见的阶级固化，类似的书挺多的。<br>安利吴晓波的激荡系列，根正苗红是不假，问题是读起来真他妈有意思。<br>简史系列同理，明明是融合了多个学科观点的历史书，但不知道为什么就像看起点爽文一样顺。能写出这样的畅销书，两个作者我是真的服气。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我觉得我今年没怎么读书，准确来讲是没逼着自己读书，结果就是读了好多虚构类(其实就是小说……)&lt;br&gt;
    
    </summary>
    
      <category term="阅读笔记" scheme="http://sheronw.github.io/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
</feed>
